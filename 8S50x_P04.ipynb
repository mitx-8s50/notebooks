{"cells": [{"cell_type": "markdown", "id": "4c879cea", "metadata": {"tags": ["learner", "md"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Guided Problem Set 4: Fitting and LMFIT Software</h1>\n"]}, {"cell_type": "markdown", "id": "88e7c942", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_4_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P4.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "038120ad", "metadata": {"tags": ["learner", "md"]}, "source": ["<table style=\"width:100%\">\n", "    <colgroup>\n", "       <col span=\"1\" style=\"width: 40%;\">\n", "       <col span=\"1\" style=\"width: 15%;\">\n", "       <col span=\"1\" style=\"width: 45%;\">\n", "    </colgroup>\n", "    <tr>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Section</th>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Problems</th>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Summary</th>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_4_1\">P4.1 Using LMFIT to Fit Data</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_4_1\">P4.1 Problems</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_4_2\">P4.2 Another LMFIT Example</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_4_2\">P4.2 Problems</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_4_3\">P4.3 Complicated Models</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_4_3\">P4.3 Problems</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_4_4\">P4.4 Interpreting Bugs with LMFIT</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#problems_4_4\">P4.4 Problems</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "</table>\n", "\n"]}, {"cell_type": "markdown", "id": "ce052a59", "metadata": {"tags": ["learner", "catsoop_00", "md"]}, "source": ["<h3>Learning Objectives</h3>\n", "\n", "In this recitation we will explore the following objectives:\n", "\n", "- Fitting with the software package `LMFIT`\n", "- A second `LMFIT` example\n", "- Fitting with complicated models, like project 1\n", "- How to interpret bugs using `LMFIT`\n"]}, {"cell_type": "markdown", "id": "f6bf7ec4", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Importing Libraries</h3>\n", "\n", "Before beginning, run the cell below to import the relevant libraries for this notebook. \n", "Optionally, set the plot resolution and default figure size.\n"]}, {"cell_type": "code", "execution_count": 7, "id": "1ed88c0a", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "import numpy as np\n", "\n", "#set plot resolution\n", "#%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure size\n", "#plt.rcParams['figure.figsize'] = (9,6)\n"]}, {"cell_type": "markdown", "id": "5c0aa877", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_4_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P4.1 Using LMFIT to Fit Data</h2>    \n", "\n", "| [Top](#section_4_0) | [Previous Section](#section_4_0) | [Problems](#problems_4_1) | [Next Section](#section_4_2) |\n"]}, {"cell_type": "markdown", "id": "287c8bde", "metadata": {"tags": ["learner", "catsoop_01", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "To get some practice fitting, suppose you have some data coming from the function $y=2x$. We'll fit a model function of $y=mx+b$"]}, {"cell_type": "markdown", "id": "de1cb0e2", "metadata": {"tags": ["learner", "catsoop_01", "md"]}, "source": ["Let's generate some example data with made-up systematic uncertainties. These uncertainties are assumed to be the standard deviations of normal distributions (a common assumption). Therefore, we draw each data point $y_i$ from a normal distribution with standard deviation equal to the uncertainty of point $i$ and mean $2 x_i$.\n", "\n", "<!--\n", "#initial code\n", "import numpy as np\n", "\n", "np.random.seed(421421)\n", "\n", "xi = np.array([2,3,4,5,6,7])\n", "yi = 2*xi\n", "\n", "y_unc = np.array([0.3, 0.4, 0.45, 0.35, 0.6, 0.5])\n", "yi = yi + np.random.randn(len(xi))*y_unc\n", "-->"]}, {"cell_type": "code", "execution_count": 1, "id": "c0d2bca4", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "import numpy as np\n", "\n", "np.random.seed(421421)\n", "\n", "xi = np.array([2,3,4,5,6,7])\n", "yi = 2*xi\n", "\n", "y_unc = np.array([0.3, 0.4, 0.45, 0.35, 0.6, 0.5])\n", "yi = yi + np.random.randn(len(xi))*y_unc"]}, {"cell_type": "markdown", "id": "5dab0be6", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='problems_4_1'></a>     \n", "\n", "| [Top](#section_4_0) | [Restart Section](#section_4_1) | [Next Section](#section_4_2) |\n"]}, {"cell_type": "markdown", "id": "e97fae6c", "metadata": {"tags": ["learner", "catsoop_01", "md"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.1.1</span>\n", "\n", "Plot the data and its error bars."]}, {"cell_type": "code", "execution_count": 14, "id": "14cb4235", "metadata": {"tags": ["draft", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>PROBLEM\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass"]}, {"cell_type": "markdown", "id": "f20809d8", "metadata": {"tags": ["learner", "catsoop_01", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "dbde5b2b", "metadata": {"tags": ["learner", "catsoop_01", "md"]}, "source": ["We'll make a model using `LMFIT` to represent the data. Models can either be selected from a [large list of functions](https://lmfit.github.io/lmfit-py/builtin_models.html) already set up by `LMFIT`, or you can make them yourself. Here we use a preset linear model.\n", "\n", "<!--\n", "#initial code\n", "from lmfit.models import LinearModel\n", "model = LinearModel()\n", "-->"]}, {"cell_type": "code", "execution_count": 1, "id": "69600f75", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "from lmfit.models import LinearModel\n", "model = LinearModel()"]}, {"cell_type": "markdown", "id": "82d09413", "metadata": {"tags": ["learner", "catsoop_01", "md"]}, "source": ["In tomorrow's lecture, you'll learn about the math behind fitting. But for now, let's let `LMFIT` black box it for us. Just know that `LMFIT` is doing a minimization algorithm behind the scenes.\n", "\n", "<b>Important:</b> set the weights equal to one over the systematic uncertainty. Not the uncertainty itself, and not the variance.\n", "\n", "<!--\n", "#initial code\n", "result = model.fit(yi, x=xi, weights=1/yerr);\n", "\n", "print(result.fit_report())\n", "-->"]}, {"cell_type": "code", "execution_count": 1, "id": "1ccac203", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "result = model.fit(yi, x=xi, weights=1/y_unc);\n", "\n", "print(result.fit_report())"]}, {"cell_type": "markdown", "id": "57bc15d1", "metadata": {"tags": ["learner", "catsoop_01", "md"]}, "source": ["Look in the `Variables` section: we have a slope of about 2 and an intercept of about zero, consistent with the true model! Very helpfully, `LMFIT` also gives you uncertainties on the fit parameters. You'll learn how `LMFIT` does this tomorrow, as well as what the `chi-square` and `reduced chi-square` entries are."]}, {"cell_type": "markdown", "id": "cef7b1e7", "metadata": {"tags": ["learner", "catsoop_01", "md"]}, "source": ["There's one more thing to do: it's always a good idea to verify that your model actually fits your data. So let's plot the data together with the model.\n", "\n", "<!--\n", "#initial code\n", "result.plot();\n", "-->"]}, {"cell_type": "code", "execution_count": 1, "id": "121ef785", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "result.plot();"]}, {"cell_type": "markdown", "id": "cdd6afe9", "metadata": {"tags": ["learner", "catsoop_01", "md"]}, "source": ["You can see that the model fits the data very well in the bottom plot, and the top plot demonstrates that deviations of the data from the model are random; they don't seem correlated with $x$ nor with each other. This is a good thing, because `LMFIT` assumed that the data points were uncorrelated with each other when performing the fit."]}, {"cell_type": "markdown", "id": "bb7b8b02", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_4_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P4.2 Another LMFIT Example</h2>    \n", "\n", "| [Top](#section_4_0) | [Previous Section](#section_4_1) | [Problems](#problems_4_2) | [Next Section](#section_4_3) |\n"]}, {"cell_type": "markdown", "id": "51dd99f2", "metadata": {"tags": ["learner", "catsoop_02", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "Fitting using a pre-determined model is all well and good, but how do you fit to data using your own model function?"]}, {"cell_type": "markdown", "id": "a7393b6c", "metadata": {"tags": ["learner", "catsoop_02", "md"]}, "source": ["Let's arbitrarily choose the function\n", "$$f(x) = \\frac{\\cos(kx)}{x^a}$$\n", "as our model, with free parameters $k > 0$ and $a > 0$.\n", "\n", "<!--\n", "#initial code\n", "import numpy as np\n", "\n", "def model_fn(x, k, a):# independent variable must be first argument\n", "    return np.cos(k * x) / x**a\n", "-->"]}, {"cell_type": "code", "execution_count": 21, "id": "bf95ad4f", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "import numpy as np\n", "\n", "def model_fn(x, k, a):# independent variable must be first argument\n", "    return np.cos(k * x) / x**a"]}, {"cell_type": "markdown", "id": "53e2374c", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='problems_4_2'></a>     \n", "\n", "| [Top](#section_4_0) | [Restart Section](#section_4_2) | [Next Section](#section_4_3) |\n"]}, {"cell_type": "markdown", "id": "a64cd39a", "metadata": {"tags": ["learner", "catsoop_02", "md"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.2.1</span>\n", "\n", "Generate some synthetic data using this model function, with 20 $x$ coordinates spaced evenly in $(0.1, \\pi]$. Use true values of $k=\\pi$ and $a=1$.\n", "\n", "Generate systematic uncertainty from a uniformly random distribution in the range $[0.1, 0.5]$ (`np.random.random()`). Assume that this uncertainty is the standard deviation of a normal distribution for the sake of randomizing your data (`np.random.randn()`).\n", "\n", "<!--\n", "#initial code\n", "import numpy as np\n", "np.random.seed(2345789)\n", "\n", "TRUE_K = np.pi\n", "TRUE_A = 1\n", "\n", "x = np.linspace(-4 * np.pi, 4 * np.pi, 20)\n", "y = #your code here\n", "yerr = #your code here\n", "-->\n", "\n", "<!--\n", "#solution\n", "import numpy as np\n", "np.random.seed(2345789)\n", "\n", "TRUE_K = np.pi\n", "TRUE_A = 1\n", "\n", "x = np.linspace(0.1, np.pi, 20)\n", "y = model_fn(x, TRUE_K, TRUE_A)\n", "\n", "y_unc = 0.1 + 0.4 * np.random.random(len(x))\n", "y = y + np.random.randn(len(x)) * y_unc;\n", "-->\n"]}, {"cell_type": "code", "execution_count": 25, "id": "cc254b6e", "metadata": {"tags": ["draft", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>PROBLEM\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "import numpy as np\n", "np.random.seed(2345789)\n", "\n", "TRUE_K = np.pi\n", "TRUE_A = 1\n", "\n", "x = np.linspace(-4 * np.pi, 4 * np.pi, 20)\n", "y = #your code here\n", "yerr = #your code here"]}, {"cell_type": "markdown", "id": "08471bd1", "metadata": {"tags": ["learner", "catsoop_02", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "a881abbd", "metadata": {"tags": ["learner", "catsoop_02", "md"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.2.2</span>\n", "\n", "Now plot your data with error bars and the true function to ensure they match.\n", "<!--\n", "#initial code\n", "import matplotlib.pyplot as plt\n", "\n", "#your code here\n", "-->\n", "\n", "<!--\n", "#solution\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "plt.errorbar(x, y, y_unc, linestyle='none')\n", "plt.plot(x, model_fn(x, TRUE_K, TRUE_A), label=\"true\")\n", "plt.scatter(x, y, label=\"data\")\n", "plt.legend()\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"y\")\n", "-->"]}, {"cell_type": "code", "execution_count": 2, "id": "8e185856", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>PROBLEM\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass"]}, {"cell_type": "markdown", "id": "cd314c6d", "metadata": {"tags": ["learner", "catsoop_02", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "e0bcf264", "metadata": {"tags": ["learner", "catsoop_02", "md"]}, "source": ["Now we need to give this model to `LMFIT`. This involves making a `Model` object, and giving it a `Parameters` object to describe the model parameters.\n", "\n", "Each parameter has `min`, `max`, and `value` arguments that specify the minimum allowable value, the maximum value, and the initial value respectively. None of these are required, but it's often a good idea to put them in if you expect your values to be within a certain range.\n", "\n", "<!--\n", "#initial code\n", "from lmfit import Model, Parameters\n", "\n", "model = Model(model_fn)\n", "\n", "params = Parameters()\n", "params.add('k', min=0, max=5, value=1)\n", "params.add('a', min=0, max=3, value=2)\n", "-->"]}, {"cell_type": "code", "execution_count": 21, "id": "3f6cf83c", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "from lmfit import Model, Parameters\n", "\n", "model = Model(model_fn)\n", "\n", "params = Parameters()\n", "params.add('k', min=0, max=5, value=1)\n", "params.add('a', min=0, max=3, value=2)"]}, {"cell_type": "markdown", "id": "6e18229d", "metadata": {"tags": ["learner", "catsoop_02", "md"]}, "source": ["Finally, let's run the fit! We reuse the code from the previous example, but we have to pass `params` into the fit function this time.\n", "\n", "<!--\n", "#initial code\n", "result = model.fit(y, params, x=x, weights=1/yerr);\n", "\n", "print(result.fit_report())\n", "\n", "result.plot();\n", "-->"]}, {"cell_type": "code", "execution_count": 21, "id": "06d4c4dd", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "result = model.fit(y, params, x=x, weights=1/y_unc);\n", "\n", "print(result.fit_report())\n", "\n", "result.plot();"]}, {"cell_type": "markdown", "id": "ff9c9bef", "metadata": {"tags": ["learner", "catsoop_02", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*Do your fit results agree with the true values? Which was determined with higher precision: $k$ or $a$? Does this make sense given your knowledge of the model function and the systematic uncertainty?*</span>"]}, {"cell_type": "markdown", "id": "910827d0", "metadata": {"tags": ["learner", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (SOLUTION)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*View the contents of this cell to see the solution*</span>\n", "    \n", "<!--\n", "#>>>SOLUTION\n", "They do agree. $a$ can be fitted with higher precision because it controls the height of the first data point very precisely; a small change in $a$ will change the height of the first data point dramatically. However, $k$ is dominated by the data points at large $x$, which have small $y$ values compared to their error bars.\n", "-->"]}, {"cell_type": "markdown", "id": "3c4d118d", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_4_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P4.3 Complicated Models</h2>    \n", "\n", "| [Top](#section_4_0) | [Previous Section](#section_4_2) | [Problems](#problems_4_3) | [Next Section](#section_4_4) |\n"]}, {"cell_type": "markdown", "id": "e4d6ad12", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "You'll be using `LMFIT` for project 1 on a complicated gravitational wave model. This section is designed to grapple with some of the same challenges you'll grapple with in project 1, so that you have some practice.\n", "\n", "We'll look at a fit model which is similar to a black hole merger waveform."]}, {"cell_type": "code", "execution_count": 32, "id": "dba78c7d", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "#code\n"]}, {"cell_type": "markdown", "id": "a2da0d91", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='problems_4_3'></a>     \n", "\n", "| [Top](#section_4_0) | [Restart Section](#section_4_3) | [Next Section](#section_4_4) |\n"]}, {"cell_type": "markdown", "id": "1219215a", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.3.1</span>\n", "\n", "Below is a complicated model function with six parameters. Add code to generate true data from the function and store it as true_yi (do not include any systematic uncertainties). Then plot your data to see what the waveform looks like. Do you see the similarity to a black hole merger?"]}, {"cell_type": "code", "execution_count": 36, "id": "fca7dd6e", "metadata": {"tags": ["draft", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>PROBLEM\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "\n", "np.random.seed(0x98a09fe)\n", "\n", "def complicated_model_fn(x, lambda_plus, lambda_minus, max_amp, omega_0, omega_max, omega_sigma):\n", "    omega = (omega_max - omega_0) * (np.exp(-np.minimum(x, 0)**2 / omega_sigma)) + omega_0\n", "    lambdas = np.array([lambda_plus if xvalue > 0 else lambda_minus for xvalue in x])\n", "    amplitude = max_amp * np.exp(-abs(x) / lambdas)\n", "    return amplitude * np.cos(omega * x)\n", "\n", "LAMBDA_PLUS_TRUE = 1.0\n", "LAMBDA_MINUS_TRUE = 4\n", "MAX_AMP_TRUE = 1.2\n", "OMEGA_0_TRUE = 3.0\n", "OMEGA_MAX_TRUE = 6.0\n", "OMEGA_SIGMA_TRUE = 4.0\n", "\n", "xi = np.linspace(-15, 5, 200)\n", "true_yi = # your code here\n", "\n", "# your plotting code here"]}, {"cell_type": "markdown", "id": "7bfda152", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "code", "execution_count": 32, "id": "810be376", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "NUMBER_SINES_TO_ADD = 10\n", "\n", "noise_frequencies = 0.5 + 7 * np.random.random(NUMBER_SINES_TO_ADD)\n", "noise_phases = 2 * np.pi * np.random.random(NUMBER_SINES_TO_ADD)\n", "noise_amplitudes = 2 * MAX_AMP_TRUE / NUMBER_SINES_TO_ADD * np.random.random(NUMBER_SINES_TO_ADD)\n", "    # The above line sets noise amplitudes so that the sum of all the noise amplitudes is on average\n", "    # equal to the maximum amplitude of the signal.\n", "\n", "yi = true_yi.copy()# yi contains the data\n", "\n", "for freq, phase, amplitude in zip(noise_frequencies, noise_phases, noise_amplitudes):\n", "    yi += amplitude * np.sin(phase + freq * xi)\n", "\n", "plt.plot(xi, yi, label='Data')\n", "plt.plot(xi, true_yi, label='True')\n", "plt.xlabel(\"Time (s)\")\n", "plt.ylabel(\"Strain\")\n", "plt.legend();"]}, {"cell_type": "markdown", "id": "8816d9a9", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["Make an `LMFIT` model and parameters for this function.\n", "\n", "<!--\n", "#initial code\n", "from lmfit import Model, Parameters\n", "\n", "model = Model(complicated_model_fn)\n", "\n", "params = Parameters()\n", "params.add('lambda_plus', min=0.1, max=5, value=1.1)\n", "params.add('lambda_minus', min=0.1, max=5, value=1)\n", "params.add('max_amp', min=0, max=2, value=1)\n", "params.add('omega_0', min=0, max=5, value=1)\n", "params.add('omega_max', min=0, max=10, value=1)\n", "params.add('omega_sigma', min=0, max=5, value=1)\n", "-->"]}, {"cell_type": "code", "execution_count": 32, "id": "1b322c93", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "from lmfit import Model, Parameters\n", "\n", "model = Model(complicated_model_fn)\n", "\n", "params = Parameters()\n", "params.add('lambda_plus', min=0.1, max=5, value=1.1)\n", "params.add('lambda_minus', min=0.1, max=5, value=1)\n", "params.add('max_amp', min=0, max=2, value=1)\n", "params.add('omega_0', min=0, max=5, value=1)\n", "params.add('omega_max', min=0, max=10, value=1)\n", "params.add('omega_sigma', min=0, max=5, value=1)"]}, {"cell_type": "markdown", "id": "8666eb45", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.3.2</span>\n", "\n", "Using the `model` and `params` variables you made above, fit to the waveform signal. Do not include a weights argument; this will set the uncertainties on all data points equal to each other. Remember to plot the result.\n", "\n", "<!--\n", "#initial code\n", "#your code here\n", "-->\n", "\n", "<!--\n", "#solution\n", "result = model.fit(yi, params, x=xi)\n", "print(result.fit_report())\n", "result.plot()\n", "-->"]}, {"cell_type": "code", "execution_count": 36, "id": "2c197446", "metadata": {"tags": ["draft", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>PROBLEM\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass"]}, {"cell_type": "markdown", "id": "1bc26ea0", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*Are you happy with the fit? Why or why not?*</span>\n", "\n", "<!--\n", "#solution\n", "No; we didn't recover the right parameters and the residuals are pretty large and don't really look like noise.\n", "-->"]}, {"cell_type": "markdown", "id": "db51588d", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.3.3</span>\n", "\n", "Let's try to get better fit results. We'll do this by running the fit many times with different initial values and taking the best fit. This is a nice, principled way to get a good fit without knowing the true fit values. \n", "\n", "First, write a function that generates a new `params` varaible with initial values chosen randomly in the ranges given in the `params_max_min` dictionary.\n", "\n", "<!--\n", "#initial code\n", "from lmfit import Model, Parameters\n", "\n", "params_min_max = {\n", "    'lambda_plus': (0.1, 5),\n", "    'lambda_minus': (0.1, 5),\n", "    'max_amp': (0, 2),\n", "    'omega_0': (0, 5),\n", "    'omega_max': (0, 10),\n", "    'omega_sigma': (0, 5)\n", "}\n", "params_trues = {\n", "    'lambda_plus': LAMBDA_PLUS_TRUE,\n", "    'lambda_minus': LAMBDA_MINUS_TRUE,\n", "    'max_amp': MAX_AMP_TRUE,\n", "    'omega_0': OMEGA_0_TRUE,\n", "    'omega_max': OMEGA_MAX_TRUE,\n", "    'omega_sigma': OMEGA_SIGMA_TRUE\n", "}\n", "\n", "def get_params():\n", "    #your code here\n", "-->\n", "\n", "<!--\n", "#solution\n", "from lmfit import Model, Parameters\n", "\n", "params_min_max = {\n", "    'lambda_plus': (0.1, 5),\n", "    'lambda_minus': (0.1, 5),\n", "    'max_amp': (0, 2),\n", "    'omega_0': (0, 5),\n", "    'omega_max': (0, 10),\n", "    'omega_sigma': (0, 5)\n", "}\n", "params_trues = {\n", "    'lambda_plus': LAMBDA_PLUS_TRUE,\n", "    'lambda_minus': LAMBDA_MINUS_TRUE,\n", "    'max_amp': MAX_AMP_TRUE,\n", "    'omega_0': OMEGA_0_TRUE,\n", "    'omega_max': OMEGA_MAX_TRUE,\n", "    'omega_sigma': OMEGA_SIGMA_TRUE\n", "}\n", "\n", "def get_params():\n", "    params = Parameters()\n", "    for p, (p_min, p_max) in params_min_max.items():\n", "        value = p_min + (p_max - p_min) * np.random.random(1)\n", "        params.add(p, min=p_min, max=p_max, value=v\n", "    return params\n", "-->"]}, {"cell_type": "code", "execution_count": 36, "id": "6c8b667e", "metadata": {"tags": ["draft", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>PROBLEM\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "from lmfit import Model, Parameters\n", "\n", "params_min_max = {\n", "    'lambda_plus': (0.1, 5),\n", "    'lambda_minus': (0.1, 5),\n", "    'max_amp': (0, 2),\n", "    'omega_0': (0, 5),\n", "    'omega_max': (0, 10),\n", "    'omega_sigma': (0, 5)\n", "}\n", "params_trues = {\n", "    'lambda_plus': LAMBDA_PLUS_TRUE,\n", "    'lambda_minus': LAMBDA_MINUS_TRUE,\n", "    'max_amp': MAX_AMP_TRUE,\n", "    'omega_0': OMEGA_0_TRUE,\n", "    'omega_max': OMEGA_MAX_TRUE,\n", "    'omega_sigma': OMEGA_SIGMA_TRUE\n", "}\n", "\n", "def get_params():\n", "    #your code here"]}, {"cell_type": "markdown", "id": "3d406686", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["Now we write a function that fits using these random parameters, returning the chi squared value and the fit result.\n", "\n", "<!--\n", "#initial code\n", "def fit(empty_arg):\n", "    model = Model(complicated_model_fn)\n", "    params = get_params()\n", "    result = model.fit(yi, params, x=xi)\n", "    return result.chisqr, result\n", "-->"]}, {"cell_type": "code", "execution_count": 32, "id": "74e9c9bb", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "def fit(empty_arg):\n", "    model = Model(complicated_model_fn)\n", "    params = get_params()\n", "    result = model.fit(yi, params, x=xi)\n", "    return result.chisqr, result"]}, {"cell_type": "markdown", "id": "2be51d62", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["Using the `multiprocessing` module to parallelize the operation and make it faster, we perform this fit with different parameters 50 times and store the results for all 50 in the results array.\n", "\n", "<!--\n", "#initial code\n", "from multiprocessing import Pool\n", "\n", "NUM_FITS = 50\n", "\n", "with Pool() as pool:\n", "    results = pool.map(fit, np.zeros(NUM_FITS))\n", "-->"]}, {"cell_type": "code", "execution_count": 32, "id": "dde35719", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "from multiprocessing import Pool\n", "\n", "NUM_FITS = 50\n", "\n", "with Pool() as pool:\n", "    results = pool.map(fit, np.zeros(NUM_FITS))"]}, {"cell_type": "markdown", "id": "72332172", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.3.4</span>\n", "\n", "Sort the `results` array generated above by the chi squared value from lowest to highest (the chi squared value is the first element of every item in `results`).\n", "\n", "Then, for the fit result with the lowest chi squared value (now the first element of sorted `results`), use the fact that the second element of the first item of `results` is the fit result object to print the `fit_report()` and show the `plot()`.\n", "\n", "<!--\n", "#initial code\n", "#your code here\n", "-->\n", "\n", "<!--\n", "#solution\n", "results = sorted(results, key=lambda x:x[0])\n", "\n", "print(results[0][1].fit_report())\n", "results[0][1].plot();\n", "-->"]}, {"cell_type": "code", "execution_count": 4, "id": "9a10dd78", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>PROBLEM\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass"]}, {"cell_type": "markdown", "id": "570ae864", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.3.5</span>\n", "\n", "For each parameter of the best fit result, display the true value (stored in `params_trues`), the fit value, the fit uncertainty, and the the difference between the true and fit values divided by the fit uncertainty.\n", "\n", "<!--\n", "#initial code\n", "#your code here\n", "-->\n", "\n", "<!--\n", "#solution\n", "for param, info in results[0][1].params.items():\n", "    print(f\"{param}:\\tTrue: {float(params_trues[param])}\\tFit: {info.value} +/- {info.stderr}\"+\\\n", "          f\"\\tSigmas: {abs(info.value - params_trues[param]) / info.stderr}\")\n", "-->"]}, {"cell_type": "code", "execution_count": 3, "id": "af980109", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>PROBLEM\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass"]}, {"cell_type": "markdown", "id": "083c3256", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*Are you happier with the fit now? What are some other things you might do to get an even better result?*</span>\n", "\n", "<!--\n", "#solution\n", "Yes; the true values are much closer to the fit values and the residuals look better. You might improve results by:\n", "- fitting over more initial parameters than 50\n", "- acknowledge uncertainty correlation\n", "- change the model function parameterization so that each parameter is more independent.\n", "- separate the hard-to-fit-for parts of the model function from the easy-to-fit-for so that the error bars on the easy-to-fit-for parameters are small\n", "-->"]}, {"cell_type": "markdown", "id": "929c8103", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_4_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">P4.4 Interpreting Bugs with LMFIT</h2>   \n", "\n", "| [Top](#section_4_0) | [Previous Section](#section_4_3) | [Problems](#problems_4_4) |\n"]}, {"cell_type": "markdown", "id": "f2df89f3", "metadata": {"tags": ["learner", "catsoop_04", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "Let's walk through a couple common bugs you might encounter when using `LMFIT`, so you know what causes them. (These are bugs in your code, not `LMFIT`)."]}, {"cell_type": "markdown", "id": "b3b2497d", "metadata": {"tags": ["learner", "catsoop_04", "md"]}, "source": ["<h3>Bug 1</h3>\n", "\n", "Let's run the code from example 3.2, but take out the parameter limits on $k$. (Make sure you run the 3.2 blocks of code before running this one.)\n", "\n", "<!--\n", "#initial code\n", "from lmfit import Model, Parameters\n", "\n", "model = Model(model_fn)\n", "params = Parameters()\n", "params.add('k')\n", "params.add('a', min=0, max=3, value=2)\n", "\n", "result = model.fit(y, params, x=x, weights=1/y_unc);\n", "\n", "print(result.fit_report())\n", "\n", "result.plot();\n", "\n", "#THROWS AN ERROR\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "d169464c", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "from lmfit import Model, Parameters\n", "\n", "model = Model(model_fn)\n", "params = Parameters()\n", "params.add('k')\n", "params.add('a', min=0, max=3, value=2)\n", "\n", "result = model.fit(y, params, x=x, weights=1/y_unc);\n", "\n", "print(result.fit_report())\n", "\n", "result.plot();\n", "\n", "#THROWS AN ERROR"]}, {"cell_type": "markdown", "id": "604e2f01", "metadata": {"tags": ["learner", "catsoop_04", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*What was the error? (Remember the phrase `generated NaN values`) What arguments can you add back to the $k$ parameter to fix this error?*</span>\n", "\n", "\n", "<!--\n", "#solution\n", "The nan error is a signifier that either your model function is incorrect or it is being used for parameters you did not intend to use it for. By setting the initial value of k closer to the true value, you resolve the problem. This error can also happen when your parameters are degenerate, as $k$ is here; $-k$ and $k$ give the same function.\n", "-->"]}, {"cell_type": "markdown", "id": "ba1735df", "metadata": {"tags": ["learner", "catsoop_04", "md"]}, "source": ["<h3>Bug 2</h3>\n", "\n", "Let's try fitting the wrong model to data. We'll generate data according to the function $f(x)=x^2$, but fit a Gaussian model instead.\n", "\n", "<!--\n", "#initial code\n", "import numpy as np\n", "from lmfit.models import GaussianModel\n", "\n", "np.random.seed(2)\n", "\n", "# Linear data\n", "xi = np.array([-2, -1, 0, 1, 2])\n", "yerr = np.array([0.3, 0.4, 0.45, 0.35, 0.6])\n", "yi = xi**2 +yerr*np.random.normal(xi.shape)\n", "\n", "# Gaussian model\n", "model = GaussianModel()\n", "\n", "results = model.fit(yi, x=xi, weights = 1/yerr);\n", "\n", "print(results.fit_report())\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "b6eb51d6", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "import numpy as np\n", "from lmfit.models import GaussianModel\n", "\n", "np.random.seed(2)\n", "\n", "# Quadratic data\n", "xi = np.array([-2, -1, 0, 1, 2])\n", "yerr = np.array([0.3, 0.4, 0.45, 0.35, 0.6])\n", "yi = xi**2 +yerr*np.random.normal(xi.shape)\n", "\n", "# Gaussian model\n", "model = GaussianModel()\n", "\n", "results = model.fit(yi, x=xi, weights = 1/yerr);\n", "\n", "print(results.fit_report())"]}, {"cell_type": "markdown", "id": "1f4b2b66", "metadata": {"tags": ["learner", "catsoop_04", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*Was an error thrown? Look more closely at the fit report. What is the warning line? What does it signify?*</span>\n", ">\n", "><span style=\"color: #90409C;\">*Add the line `results.plot();` to the above block of code. Does this make it easier to diagnose the problem?*</span>\n", "\n", "\n", "<!--\n", "#solution\n", "`##  Warning: uncertainties could not be estimated.` It indicates that your fit was quite bad, as do your chi squared and reduced chi-squared values. By looking at those or by plotting the function, the poor fit quality becomes more recognizable.\n", "-->"]}, {"cell_type": "markdown", "id": "29ca25e8", "metadata": {"tags": ["learner", "catsoop_04", "md"]}, "source": ["<h3>Bug 3</h3>\n", "\n", "`LMFIT` relies on the fact that your model function needs to handle `np` arrays. What happens if yours doesn't?\n", "\n", "<!--\n", "#initial code\n", "import numpy as np\n", "from lmfit import Model, Parameters\n", "\n", "TRUE_HEIGHT = 1.0\n", "\n", "def heaviside(x, height):\n", "    if x > 0:\n", "        return height\n", "    return 0.0\n", "\n", "xi = np.linspace(-5, 5, 10)\n", "try:\n", "    yi = heaviside(xi, TRUE_HEIGHT)\n", "except:\n", "    yi = np.array([heaviside(x, TRUE_HEIGHT) for x in xi])\n", "yerr = np.random.random(len(xi)) * 0.4 + 0.1\n", "yi += np.random.randn(len(xi)) * yerr\n", "\n", "model = Model(heaviside)\n", "params = Parameters()\n", "params.add('height', min=0.1, max=10, value=2)\n", "\n", "results = model.fit(yi, params, x=xi, weights = 1/yerr);\n", "\n", "print(results.fit_report())\n", "\n", "results.plot();\n", "\n", "#THROWS AN ERROR\n", "-->"]}, {"cell_type": "code", "execution_count": null, "id": "27e59ac7", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "import numpy as np\n", "from lmfit import Model, Parameters\n", "\n", "TRUE_HEIGHT = 1.0\n", "\n", "def heaviside(x, height):\n", "    if x > 0:\n", "        return height\n", "    return 0.0\n", "\n", "xi = np.linspace(-5, 5, 10)\n", "try:\n", "    yi = heaviside(xi, TRUE_HEIGHT)\n", "except:\n", "    yi = np.array([heaviside(x, TRUE_HEIGHT) for x in xi])\n", "yerr = np.random.random(len(xi)) * 0.4 + 0.1\n", "yi += np.random.randn(len(xi)) * yerr\n", "\n", "model = Model(heaviside)\n", "params = Parameters()\n", "params.add('height', min=0.1, max=10, value=2)\n", "\n", "results = model.fit(yi, params, x=xi, weights = 1/yerr);\n", "\n", "print(results.fit_report())\n", "\n", "results.plot();\n", "\n", "#THROWS AN ERROR"]}, {"cell_type": "markdown", "id": "cf46d7dc", "metadata": {"tags": ["learner", "catsoop_04", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*What was the error? Modify the model function so that it works for numpy arrays. There are several ways to do this, with varying levels of computational speed.*</span>\n", ">\n", "><span style=\"color: #90409C;\">*Remember that as a fallback, you can always manually turn a python list into a numpy array by calling `np.array(list)` where `list` is a python list.*</span>\n", "\n", "\n", "\n", "<!--\n", "#solution\n", "The error was this `a.any()` / `a.all()`. This error is a bit of a red herring; I think it's simpler to change your fit function to the following.\n", "\n", "```\n", "def heaviside(x, height):\n", "    return np.array([height if x_val > 0 else 0 for x_val in x])\n", "```\n", "-->"]}, {"cell_type": "markdown", "id": "a48236b5", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='problems_4_4'></a>   \n", "\n", "| [Top](#section_4_0) | [Restart Section](#section_4_4) |\n"]}, {"cell_type": "markdown", "id": "c5344cf6", "metadata": {"tags": ["learner", "catsoop_04", "md"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Problem 4.4.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": 47, "id": "a80f3856", "metadata": {"tags": ["draft", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>PROBLEM\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "617a8e32", "metadata": {"tags": ["learner", "catsoop_04", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}