{"cells": [{"cell_type": "markdown", "id": "d6d3c5b9", "metadata": {"tags": ["learner", "md"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 2: Binomial, Poisson, and Gaussian Distributions</h1>\n"]}, {"cell_type": "markdown", "id": "8f15f03f", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_2_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "63e300db", "metadata": {"tags": ["learner", "md"]}, "source": ["<table style=\"width:100%\">\n", "    <colgroup>\n", "       <col span=\"1\" style=\"width: 40%;\">\n", "       <col span=\"1\" style=\"width: 15%;\">\n", "       <col span=\"1\" style=\"width: 45%;\">\n", "    </colgroup>\n", "    <tr>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Section</th>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Exercises</th>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Summary</th>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_1\">L2.1 Introduction to Binomial Distribution</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_1\">L2.1 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_2\">L2.2 Applications Using the Binomial Distribution</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_2\">L2.2 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_3\">L2.3 The Poisson Distribution</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_3\">L2.3 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_4\">L2.4 Poisson Distribution Continued</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_4\">L2.4 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_5\">L2.5 The Gaussian Distribution</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_5\">L2.5 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_6\">L2.6 Uncertainties in Measurement</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_6\">L2.6 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_2_7\">L2.7 Propagating Uncertainties</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_2_7\">L2.7 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "</table>\n", "\n"]}, {"cell_type": "markdown", "id": "a864232e", "metadata": {"tags": ["learner", "catsoop_00", "md"]}, "source": ["<h3>Learning Objectives</h3>\n", "\n", "Text needed\n"]}, {"cell_type": "markdown", "id": "4f25a8db", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Importing Libraries</h3>\n", "\n", "Before beginning, run the cell below to import the relevant libraries for this notebook. \n", "Optionally, set the plot resolution and default figure size.\n"]}, {"cell_type": "code", "execution_count": null, "id": "fec93314", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "import numpy as np\n", "\n", "#set plot resolution\n", "#%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure size\n", "#plt.rcParams['figure.figsize'] = (9,6)\n"]}, {"cell_type": "markdown", "id": "549f4d68", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Slides</h3>\n", "\n", "Run the code below to view the slides for this lesson."]}, {"cell_type": "code", "execution_count": null, "id": "b9f82529", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L02/slides1.html', width=975, height=550)"]}, {"cell_type": "markdown", "id": "cbea03c9", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_2_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.1 Introduction to Binomial Distribution</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_0) | [Exercises](#exercises_2_1) | [Next Section](#section_2_2) |\n"]}, {"cell_type": "markdown", "id": "7d60d26b", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "<!--<img src=\"https://external-preview.redd.it/Kt_QUdsFmAI4v9hPw-JbYA2wC9blaF8iIvnVdla2aaE.jpg?auto=webp&s=da7915bb8a27e47d88adaf6f58bab193b7d1f35f\" width=\"500\"/>-->\n", "\n", "Often we perform measurements having some probability. Lets say we perform many measurements each with the same probability. What will be our distribution?  Since this is a physics class, we will not go into the depth of the math behind this, but let's at least walk through a basic derivation.\n"]}, {"cell_type": "markdown", "id": "77b3064b", "metadata": {"tags": ["learner", "md"]}, "source": ["Let's say you flip a coin 10 times and the probability of heads is $p$. Let's say 3 times you get a heads distribution. That means the other 7 times you got a tails distribution.  \n", "* What are the number of different cases there are 3 heads?\n", "\n", "In this case we have 3 heads out of 10 flips so we have have $_{10}C_{3}=\\frac{10!}{3!7!}=120$ ([details](https://en.wikipedia.org/wiki/Combination)). As a brief reminder of how this works, there are $10!$ different ordered combinations of numbers 1 through 10. Lets say we identify 3 of those 10 digits as special for whatever reason (e.g. lets take the first 3 digits). Then there are $3!$ ways to order these digits (e.g. (1,2,3),(1,3,2),....) and there are $7!$ ways to order the remaining 7 digits. As a consquence for all 10 digits, there are $_{10}C_{3}$ different ways to order a group of 3, and 7 digits combined where the 3 and 7 digits are distinct from one another (ie 1,2,3 is heads and 4...10 is tails). More generally, we have for $n$ flips and $m$ cases the total number of combinations will be written as $\\frac{n!}{m!(n-m)!}$. \n", "\n", "* What is the probability of this scenario?\n", "\n", " * Each flip of the coin has equal probability giving heads. Lets say that this probability is $p$. To get one head and one tail in two flips  the probability would be the multiplicative probability to get a head  ($p$) and a tails ($(1-p)$) then $\\times$ by the number of distinct combinations that would give you a heads and a tails. In this case, the number of combinations is $2$, a heads first and a tails second, *or* a tails frist and a heads second. This yields a total probability of $p(1-p)\\times N_\\mathrm{combo}=2p(1-p)$.\n", "\n", " * In the case where there are 3 heads, the probability is the probability of 3 heads $p^{3}$ and the probability of 7 no heads $(1-p)^{7}$ and for $n$ flips and $m$ cases we have $p^{m}(1-p)^{n}\\times N_\\mathrm{combo}$. \n", "\n", "* What is the distribution?\n", " * If we combine everything for our specific case, we have $_{10}C_{3}\\times p^3(1-p)^7$ \n", " * Putting everything together we have the binomial distribution as a function of $p$ given by $f(m)=p^{m}(1-p)^{n}\\frac{n!}{m!(n-m)!}$\n", "\n", "Lets actually compute this for a few cases?\n"]}, {"cell_type": "code", "execution_count": null, "id": "149413af", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "import numpy as np\n", "from scipy.special import comb\n", "print(\"Test comb:\",comb(2,1),\"True: 2\",comb(3,2),\"True: 3\",comb(10,3),\"True: 120\")\n", "\n", "#for p=0.5, what is the probabiity of 3 heads out of 10 draws?\n", "def prob(p=0.5,nheads=3,ntotal=10):\n", "    pheads=np.power(p,nheads)\n", "    ptails=np.power(p,ntotal-nheads)\n", "    combos=comb(ntotal,nheads)\n", "    return combos*ptails*pheads\n", "\n", "print(\"Probability of 3 heads in 10 draws is:\",prob(nheads=3,ntotal=10))\n", "#Question, plot the probability of 3 heads out of 10 for varying probability value, why is the shape like that?\n"]}, {"cell_type": "markdown", "id": "d71379ab", "metadata": {"tags": ["learner", "md"]}, "source": ["Out of all of this math, we have derived the binomial distribution. This is the first emperical distribution we will need for this class. In fact, all of the other distributions we will study are built upon the binomial distribution. Let's compute the expectation and variance of this distribution, first we can define the distribution.\n", "\\begin{equation}\n", "f(p,n,m) = \\frac{n!}{m!(n-m)!}p^{m}(1-p)^{n-m}\\\\\n", "\\end{equation}\n", "Now let's compute the expectaion over $m$ for $p$ and $n$ fixed, defined as $E[m;p,n]$ the semicolon denotes fixed. \n", "\\begin{equation}\n", "E[m;p,n]=\\int_0^{n} p^{m}(1-p)^{n}\\frac{n!}{m!(n-m)!} \\mathrm{heads}(m) dm \\\\\n", "\\end{equation}\n", "Where $\\mathrm{heads}(m)$ is a function that we define as the expected value given a heads or tails observation. In this case, we will define this function as $1$ for heads and $0$ for tails. This is a complicated form, but in the case of just just choosing, one head we have. \n", "\\begin{equation}\n", "E[m;p,n=1]= p\\times1+(1-p)\\times0\\\\\n", "E[m;p,n=1]= p\n", "\\end{equation} \n", "\n", "Now lets introduce a new function that is defined as the sum of $n$ individual experiments, we can define the function $f(x)=\\sum_{i} \\rm{heads}(x_{i})$. The expectation for this is\n", "\\begin{eqnarray}\n", "E[f(x)]&=&\\sum_{0}^{n} p\\times 1+(1-p)\\times 0 \\\\\n", "E[f(x)]&=&np\\\\\n", "\\end{eqnarray}\n", "That means the average value over $n$ tries $\\bar{x}=f(x)/n=p$ or its just the value $p$. \n", "\n", "In a similar way we can define the variance as: \n", "\\begin{eqnarray}\n", "V[f(x)]&=&\\sum_{i=0}^{n} (x-\\mu)^2 \\\\\n", "V[f(x)]&=&\\sum_{i=0}^{n} p\\times(1-\\mu)^2 + (1-p) \\times (0-\\mu)^2 \\\\\n", "V[f(x)]&=&\\sum_{i=0}^{n} p \\times (1-p)^2 + (1-p) \\times (0-p)^2 \\\\\n", "V[f(x)]&=&\\sum_{i=0}^{n} (1-p)\\times (p^2 +p(1-p))  \\\\\n", "V[f(x)]&=&\\sum_{i=0}^{n} (1-p)\\times p   \\\\\n", "V[f(x)]&=&np(1-p)\n", "\\end{eqnarray}\n", "or in other words, we consider performing $n$ independent measurements, we can compute the variance over this distribution as $V[f(x)/n]=V[f(x)]/n=p(1-p)$\n", "\n", "It's all fun to do math, but the point of this class is to do it with computers, so let's do the same derivations numerically. Note we plot these as discrete lines rather than continuous points, since the binomial distribution is discrete and only defined for discrete numbers. \n", "\n"]}, {"cell_type": "code", "execution_count": null, "id": "9fbc58b5", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#We are going to use scipy stats package\n", "import scipy.stats as stats\n", "import matplotlib.pyplot as plt\n", "n=30\n", "p=0.25\n", "#Scipy has a binomial, but since this is a discrete distribution we use pmf (probability mass function) rather than pdf\n", "k=np.arange(0,n)\n", "binomial=stats.binom.pmf(k,n,p)\n", "#let's get the integral of this guy\n", "norm=0\n", "exp=0\n", "var=0\n", "for i0 in range(n):\n", "    norm+=stats.binom.pmf(i0,n,p)\n", "    exp+=i0*stats.binom.pmf(i0,n,p)\n", "for i0 in range(n):\n", "    pVal=stats.binom.pmf(i0,n,p)\n", "    var+=(i0-exp/norm)*(i0-exp/norm)*pVal\n", "\n", "#Print it out\n", "print(\"norm:\",norm,\"expectation:\",exp/norm,\"Var:\",var/norm)\n", "#Now lets check with the expectation\n", "print(\"norm: 1.000000, expectation:\",n*p,\"Var:\",n*p*(1-p))\n", "\n", "plt.plot(k,binomial,'o')\n", "plt.vlines(k,0, binomial)\n", "plt.ylim(bottom=0)\n", "\n", "plt.xlabel(\"Number of successes\")\n", "plt.ylabel(\"Probability\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "267e36b8", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='exercises_2_1'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_1) | [Next Section](#section_2_2) |\n"]}, {"cell_type": "markdown", "id": "0c07af0d", "metadata": {"tags": ["learner", "md", "catsoop_01"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 2.1.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": null, "id": "f54ecf2a", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "09d7cba0", "metadata": {"tags": ["learner", "catsoop_01", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "3ab245b0", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_2_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.2 Applications Using the Binomial Distribution</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_1) | [Exercises](#exercises_2_2) | [Next Section](#section_2_3) |\n"]}, {"cell_type": "markdown", "id": "a5784ae9", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "Now, let's actually do some more difficult problems that flipping a coin. Also, lets actually think about this in a real life setting. Lets say that you are observing [fast radio bursts](https://en.wikipedia.org/wiki/Fast_radio_burst), and based on the wikipedia page [here](https://en.wikipedia.org/wiki/List_of_fast_radio_bursts) you observe about 19 fast radio bursts per year. What is the probability that you observe 2 fast radio bursts (FRB) within a day of each other? \n", "\n", "The trick to this problem is think of each day as flipping a coin. Where the probability of heads is instead the probability of finding a FRB. We can caculate the average probability by noting that over a period 365 days (i.e. 365 experiments), we see 19 FRBs, or in other words:\n", "\\begin{eqnarray}\n", "E[f(x;n=365)]&=&np \\\\\n", "             &=&19 \\\\\n", "             &=&365\\times p \\\\\n", "            p&=&\\frac{19}{365}\n", "\\end{eqnarray}\n", "So the probability of $2$ in a row is just 0.3\\%(see below). Moreover the probability of 2 observations in 7 days is (see below) 4.3%.\n"]}, {"cell_type": "code", "execution_count": null, "id": "99c8c63b", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "def prob(ndays=2,nobs=2,p=19/365):\n", "    return stats.binom.pmf(nobs,ndays,p)\n", "\n", "print(\"2 observations in 2 days:\",prob())\n", "print(\"2 observations in 7 days:\",prob(7))\n", "print(\"19 observations in 365 days:\",prob(365,19))\n"]}, {"cell_type": "markdown", "id": "a9f60a5a", "metadata": {"tags": ["learner", "md"]}, "source": ["Now, lets ask the important physics question. Let's say you observed 2 FRBs back to back, given the probability of this occurance is so rare, is something else happening in the universe? [Read here](https://en.wikipedia.org/wiki/Fast_radio_burst#FRB_201124)\n", "\n", "Secondly, why is the probability of 19 observations in 365 days so low? (only 10%). To understand this let's make a plot. \n"]}, {"cell_type": "code", "execution_count": null, "id": "78aa681e", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "p=19/365\n", "n=365\n", "k=np.arange(0,50)\n", "binomial=stats.binom.pmf(k,n,p)\n", "\n", "def plotBinomial(iX,iBinomial,label='Binomial',color='black'):\n", "    plt.plot(iX,iBinomial,'o')\n", "    plt.vlines(iX,0, iBinomial,label=label,color=color)\n", "    plt.ylim(bottom=0)\n", "    plt.xlabel(\"Number of observations per year\")\n", "    plt.ylabel(\"Probability\")\n", "\n", "plotBinomial(k,binomial)\n"]}, {"cell_type": "markdown", "id": "c7958a63", "metadata": {"tags": ["learner", "md"]}, "source": ["Getting exatly 19 observations is unlikely because there is variation. What we really want to do is integrate the number of observations that are either greater or less than 19. This is the cumulative distribution function. \n", "\\begin{equation}\n", "\\mathrm{CDF}(\\mathrm{binomial}(x)) = \\int_x^{\\infty} \\mathrm{binomial}(u;p,k) du \n", "\\end{equation}\n", "the nice thing is that this is all built into our statistics code, lets plot it. \n"]}, {"cell_type": "code", "execution_count": null, "id": "8d21604c", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "p=19/365\n", "n=365\n", "k=np.arange(0,50)\n", "binomial=stats.binom.pmf(k,n,p)\n", "binomialcdf=stats.binom.cdf(k,n,p)\n", "print(\"cdf at 19:\",stats.binom.cdf(19,n,p))\n", "\n", "plt.plot(k,binomialcdf,'o', label=\"Binomial CDF\")\n", "plt.vlines(k,0, binomialcdf, color=plt.gca().lines[-1].get_color())\n", "plt.ylim(bottom=0)\n", "\n", "plt.plot(k,binomial,'o', label=\"Binomial PMF\")\n", "plt.vlines(k,0, binomial, color=plt.gca().lines[-1].get_color())\n", "plt.ylim(bottom=0)\n", "\n", "plt.xlabel(\"Number of observations per year\")\n", "plt.ylabel(\"Probability\")\n", "plt.legend()\n", "plt.show()\n", "\n", "\n", "mean = np.average(k, weights=binomial)\n", "variance = np.average((k-mean)**2, weights=binomial)\n", "print(\"mean:\",mean,\"stddev:\",np.sqrt(variance))\n", "\n"]}, {"cell_type": "markdown", "id": "671cb843", "metadata": {"tags": ["learner", "md"]}, "source": ["So now we see clearly the CDF is at approximately 50%. It's not exactly 50% for the simple fact that this is a discrete distribution. However the expectation wil be at exactly 19. "]}, {"cell_type": "markdown", "id": "4c541413", "metadata": {"tags": ["learner", "md"]}, "source": ["### Challenge Question\n", "\n", "Lets do another related problem. With the current rate of gravitataional wave (GW) detection we observe a GW once per week. What is probability of 3 or more graviational waves in one week? Plot the distribution. Additionally, what is the distribution for GW events over the whole year, and the mean and variance? "]}, {"cell_type": "code", "execution_count": null, "id": "301a3000", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "import scipy.stats as stats\n", "#solution\n", "n=7.\n", "p=1./7.\n", "k=np.arange(0,10)\n", "binomial=stats.binom.pmf(k,n,p)\n", "total1=0\n", "for i0 in range(len(k)):\n", "    if k[i0] > 2:\n", "        total1+= binomial[i0]\n", "print(\"binomial:\",total1)\n", "\n", "plotBinomial(k,binomial)\n", "plt.show()\n", "\n", "#now what about for GWs in a year\n", "n=365. #we don't need to divide by day!\n", "p=1/7.\n", "k=np.arange(0,100)\n", "binomial=stats.binom.pmf(k,n,p)\n", "\n", "plotBinomial(k,binomial)\n", "plt.show()\n", "\n", "average  = np.average(k, weights=binomial)\n", "variance = np.average((k-average)**2, weights=binomial)\n", "print(\"mean:\",average,\"stddev:\",np.sqrt(variance))\n", "\n", "hide_toggle()\n", "\n"]}, {"cell_type": "markdown", "id": "e2af4818", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='exercises_2_2'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_2) | [Next Section](#section_2_3) |\n"]}, {"cell_type": "markdown", "id": "971d3ebf", "metadata": {"tags": ["learner", "md", "catsoop_02"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 2.2.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": null, "id": "b1378c33", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "910a11da", "metadata": {"tags": ["learner", "catsoop_02", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "d55932f2", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_2_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.3 The Poisson Distribution</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_2) | [Exercises](#exercises_2_3) | [Next Section](#section_2_4) |\n"]}, {"cell_type": "markdown", "id": "a1b3c733", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "The ugly thing about the binomial distribution is that it has these damn factorials. One way to get rid of the factorials is to do an approximation of the binomial distribution. We can define this by taking a limit over the number of experiments going to infinity $n\\rightarrow\\infty$. To do this we\n", "\\begin{equation}\n", "{\\rm define~} \\lambda = \\lim_{n\\rightarrow\\infty} np \\rightarrow p=\\frac{\\lambda}{n} \\\\\n", "\\end{equation}\n", "\n", "Now in this limiting case, we can replace the binomial distribution with an approximate form that has less factorials:\n", "\\begin{eqnarray}\n", "\\lim_{n\\rightarrow\\infty}\\frac{n!}{m!(n-m)!}p^{m}(1-p)^{n} & = & \\frac{n(n-1)...(n-m)}{m!}\\left(\\frac{\\lambda}{n}\\right)^{m}\\left(1-\\frac{\\lambda}{n}\\right)^{n} \\\\\n", "&\\approx&\\frac{n^m}{m!}\\frac{\\lambda^{m}}{n^{m}}\\left(1-\\frac{\\lambda}{n}\\right)^{n} \\\\\n", "&\\approx&\\frac{\\lambda^{m}}{m!}e^{-\\lambda} \\\\\n", "f(m;\\lambda=np) & = & \\frac{\\lambda^{m}}{m!}e^{-\\lambda}\n", "\\end{eqnarray}\n", "This form is known as the Poisson distribution, and is achieved by taking the binomial distribution to the large $n$ limit. We still have a pesky factorial, but one factorial is better than three factorials. \n", "\n", "Since, we can treat the Poisson distribution just like the binomial distribution. We can use the above computations for the mean and variance of $n\\rightarrow\\infty$ experiments sampling a poission distribution as (noting $p\\rightarrow0$ in the large $n$ limit)\n", "\\begin{equation}\n", "E[f(x)]=\\lambda \\\\\n", "V[f(x)]=\\lambda\n", "\\end{equation}\n", "What is most important from this observation is that the standard deviation of the distribution goes as the $\\sqrt{\\lambda}$ or root of the mean of the distribution. This will play a critical role going forward. \n", "\n", "Now let's see how it compares to a binomial in our previous plots. Lets use our FRB example $p=19/365$. Alternatively, lets also consider the probability of a sunny day in Boston $p=200/365$.\n", "\n", "<br>\n", "<!--end-block-->\n"]}, {"cell_type": "code", "execution_count": null, "id": "0f0862a0", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Lets make a function for plotting\n", "def plotWeekYear(p):\n", "    #Week comparison\n", "    n=7\n", "    k=np.arange(0,n+1)\n", "    binomial_week=stats.binom.pmf(k,n,p)\n", "    poisson_week=stats.poisson.pmf(k,n*p)#note we give lambda=n*p\n", "    plotBinomial(k,binomial_week,label='Binomial',color='blue')\n", "    plotBinomial(k,poisson_week,label='Poisson',color='orange')\n", "    plt.legend(loc='upper right')\n", "    plt.xlabel('number of observations per week')\n", "    plt.show()\n", "\n", "    n=365\n", "    k=np.arange(0,2*p*n)\n", "    binomial_year=stats.binom.pmf(k,n,p)\n", "    poisson_year=stats.poisson.pmf(k,n*p)#note we give lambda=n*p\n", "    plotBinomial(k,binomial_year,label='Binomial',color='blue')\n", "    plotBinomial(k,poisson_year,label='Poisson',color='orange')\n", "    plt.legend(loc='upper right')\n", "    plt.show()\n", "\n", "    average  = np.average(k, weights=binomial_year)\n", "    variance = np.average((k-average)**2, weights=binomial_year)\n", "    print(\"Yearly Binomial mean:\",average,\"stddev:\",np.sqrt(variance))\n", "    \n", "    average  = np.average(k, weights=poisson_year)\n", "    variance = np.average((k-average)**2, weights=poisson_year)\n", "    print(\"Yearly Poisson mean:\",average,\"stddev:\",np.sqrt(variance))\n", "\n", "    \n", "#First FRBs\n", "p=19/365\n", "plotWeekYear(p)\n", "#Now lets do sunny days\n", "p=200/365\n", "plotWeekYear(p)\n"]}, {"cell_type": "markdown", "id": "f4059087", "metadata": {"tags": ["learner", "md"]}, "source": ["So we see that the poisson approximation is really quite good for the case where the $p\\ll1$. However, when $p$ is large and the number of events is small, we can be quite off. Just look at the number of sunny days per week. The binomial distributions gives about two percent vs nearly eight percent. This is a dramatic difference. Which one of these is correct for weather? (Answer: neither are good because weather from the previous day tells you about the current, its not a random process on the day to day level)"]}, {"cell_type": "markdown", "id": "bb4ade39", "metadata": {"tags": ["learner", "md"]}, "source": ["### Challenge Question\n", "\n", "Compare Poisson for gravitational wave observations, how off will you be if you approximate this effect with a Poisson? \n"]}, {"cell_type": "code", "execution_count": null, "id": "b6bc65f1", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#Answer\n", "#Now with the current rate of Gravitataional wave detection we observe a GW once per week\n", "#What is probability of 3 or mroe graviational waves in one week\n", "#In this case this is the probability of 3 random events happening in a short period of time, since we know \n", "#One way to phrase this is that the probability of a GW on a day is 1/7 and we hvae 7 days in a week\n", "#What is the probability of 3 or more. The distribution for this is\n", "n=7.\n", "p=1./7.\n", "plotWeekYear(p)\n", "hide_toggle()"]}, {"cell_type": "markdown", "id": "54e627c0", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='exercises_2_3'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_3) | [Next Section](#section_2_4) |\n"]}, {"cell_type": "markdown", "id": "8aa6353b", "metadata": {"tags": ["learner", "md", "catsoop_03"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 2.3.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": null, "id": "dc870c7a", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "ac05a6bd", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "7801d58d", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_2_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.4 Poisson Distribution Continued</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_3) | [Exercises](#exercises_2_4) | [Next Section](#section_2_5) |\n"]}, {"cell_type": "markdown", "id": "4c545768", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "Now, why are we spending so much time on Poisson distributions. Let's say I have a distribution that is flat and I sampled from that distribution 10000 times, and then made a histogram with 100 bins. Lets make a distribution like that? \n"]}, {"cell_type": "code", "execution_count": null, "id": "12d02cbd", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "fig, ax = plt.subplots(figsize=(9,6))\n", "N=10000\n", "nbins=100\n", "sample  = np.random.uniform (0,1,N)\n", "\n", "def plotHist(iSample,iNBins):\n", "    histy, bin_edges = np.histogram(iSample, bins=iNBins)\n", "    bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "    ax.set_ylim([0,2*N/nbins])\n", "    plt.plot(bin_centers,histy,drawstyle = 'steps-mid')\n", "    plt.xlabel(\"x\")\n", "    plt.ylabel(\"Events/bin\")\n", "    plt.show()\n", "    return bin_centers, histy\n", "\n", "_,_ = plotHist(sample,nbins)\n"]}, {"cell_type": "markdown", "id": "da42eb57", "metadata": {"tags": ["learner", "md"]}, "source": ["What is the variation of each of these bins? To think about this, each sampling has a 1/100 probability of being in any one of those bins. \n", "\n", "Let's look at the mean and variance over teh bins. What is the distribution of the variations over these bins? \n"]}, {"cell_type": "code", "execution_count": null, "id": "e0337645", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Solution\n", "#copy and past above distribution\n", "fig, ax = plt.subplots(figsize=(9,6))\n", "N=1000000\n", "nbins=100\n", "sample  = np.random.uniform (0,1,N)\n", "histx, histy = plotHist(sample,nbins)\n", "\n", "\n", "def normhist(iVars,iNbins=30,iNormalize=True):\n", "    y0, bin_edges = np.histogram(iVars, bins=iNbins)\n", "    bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "    norm0 = 1 \n", "    if iNormalize:\n", "        norm0=len(iVars)*(bin_edges[-1]-bin_edges[0])/iNbins\n", "    plt.errorbar(bin_centers,y0/norm0,yerr=y0**0.5/norm0,drawstyle = 'steps-mid',c='red')\n", "    return bin_centers,y0,bin_edges\n", "\n", "residx,residy,_=normhist(histy)\n", "haverage  = np.average(residx, weights=residy)\n", "hvariance = np.average((residx-haverage)**2, weights=residy)\n", "print(\"Actual mean:\",haverage,\"Variance:\",hvariance) \n", "\n", "#Now since we have 100 bins with p=1/100 and we sample 1000 times we have lamb=np= N (1/nbins)\n", "lamb=N/nbins # Number events/bin = 100\n", "k=np.arange(0.85*N/nbins,1.15*N/nbins)\n", "poisson=stats.poisson.pmf(k,lamb)#lambda = n * p = 10000 * (1/100)\n", "paverage  = np.average(k, weights=poisson)\n", "pvariance = np.average((k-paverage)**2, weights=poisson)\n", "print(\"Poisson mean:\",paverage,\"Variance:\",pvariance)\n", "\n", "plt.plot(k,poisson,'o')\n", "# plt.vlines(k,0, poisson)\n", "plt.ylim(bottom=0)\n", "\n", "plt.xlabel(\"Mean per bin\")\n", "plt.ylabel(\"probability\")\n", "plt.show()"]}, {"cell_type": "markdown", "id": "cc403c95", "metadata": {"tags": ["learner", "md"]}, "source": ["Now this brings us to a very important plot. If we have a histogram with $N$ events what are the fluctuations in that bin? \n", "\n", "If it is Poisson, then the variance is going to be $N$ and the standard deviation is going to be $\\sqrt{N}$. As a consequence, we can characterize the fluctuations per bin by the standard deviation. Thus, whenever we have a plot with data and we want to plot the expected fluctuations per bin, we plot the Poisson flucutations. The previous distribution would thus look like:"]}, {"cell_type": "code", "execution_count": null, "id": "342d96ea", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#And so the bins are poisson fluctuated. This is why when we plot data in a histogram we put error bars \n", "#Corresponding the poission uncertainty in a bin\n", "N=10000\n", "nbins=100\n", "sample  = np.random.uniform (0,1,N)\n", "histy, bin_edges = np.histogram(sample, bins=nbins)\n", "yerr=np.sqrt(histy)\n", "bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "ax.set_ylim([0,2*N/nbins])\n", "\n", "#Here is the command\n", "plt.errorbar(bin_centers,histy,yerr=yerr,marker='.',c='black',linestyle = 'None',label='Data')\n", "\n", "k=np.arange(0,1,0.01)\n", "vals=np.full((100),N/nbins)\n", "plt.plot(k,vals,'o--',label=\"Expected value\")\n", "plt.ylim(0,150)\n", "plt.xlabel(\"x\")\n", "plt.ylabel(\"Events/bin\")\n", "plt.legend(loc='lower right')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "ca231f1b", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='exercises_2_4'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_4) | [Next Section](#section_2_5) |\n"]}, {"cell_type": "markdown", "id": "9b879ebc", "metadata": {"tags": ["learner", "md", "catsoop_04"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 2.4.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": null, "id": "b4541317", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "df2fe730", "metadata": {"tags": ["learner", "catsoop_04", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "f0d13378", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_2_5'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.5 The Gaussian Distribution</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_4) | [Exercises](#exercises_2_5) | [Next Section](#section_2_6) |\n"]}, {"cell_type": "markdown", "id": "8c6cddf6", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "The above Poisson distribution is a very powerful distribution. However, we often view it as a subset of the Normal or Gaussian distribution, given by the form: \n", "\n", "\\begin{equation}\n", "\\mathcal{N}(x,\\mu,\\sigma)=\\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{\\frac{(x-\\mu)^2}{2\\sigma^2}}\n", "\\end{equation}\n", "\n", "It has the very important properties, that you can derive yourselves: \n", "\\begin{equation}\n", "E[N(x,\\mu,\\sigma]=\\mu \\\\\n", "V[N(x,\\mu,\\sigma]=\\sigma^2 \\\\\n", "\\end{equation}\n", "\n", "It is effectively a Poisson distribution where the variance is now not $\\sigma=\\lambda$, but instead a free parameter $\\sigma$. It is ofen viewed as a generalized version of the Poisson distribution. There are many names for this distribution. Mathematicians and statistician's often call this the normal distribution. The public frequently refer to this as the bell curve. Physicists call this the Gaussian distribution. These notes will refer to it as Gaussian, since Normal can be easily confused (especially with non-native English speakers). \n", "\n", "While the Gaussin distribution looks simple, there are several things to notice about it. The most important is that the CDF\n", "\n", "\\begin{equation}\n", "\\mathcal{N}(x,\\mu,\\sigma)=\\int_{x}^{\\infty} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{\\frac{(u-\\mu)^2}{2\\sigma^2}} du\n", "\\end{equation}\n", "\n", "does not have a closed analytic form. In fact, we have to integrate this numerically. What makes the normal distribution so power is that it appears all over the place, let's understand the normal distribution in the context of the most important theorem in all of statistics.\n"]}, {"cell_type": "markdown", "id": "6031ed00", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Central Limit Theorem</h3>\n", "\n", "Recall in lecture 1, we derived the sum distribution of two objects. This gave us a triangle distribution, what happens when we consider the sum of more than just two numbers, some very large set of numbers. \n"]}, {"cell_type": "code", "execution_count": null, "id": "d737ee3d", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "import math\n", "\n", "def plotSum(iN):\n", "    ntoys=10000\n", "    sums=np.array([])\n", "    for i0 in range(ntoys):\n", "        pToy = np.random.uniform(0,10,iN)\n", "        sums = np.append(sums,pToy.sum())\n", "    _,_,binrange=normhist(sums) #plots a normalized hist\n", "    k=np.linspace(binrange[0],binrange[-1], 50)\n", "    normal=stats.norm.pdf(k,sums.mean(),sums.std())\n", "    plt.plot(k,normal,'o-')\n", "    plt.xlabel(\"Number of successes\")\n", "    plt.ylabel(\"Probability\")\n", "    print(\"Summing:\",iN,\" numbers with mean:\",sums.mean(),\" and std-deviation\",sums.std(),sums.mean()/math.sqrt(3*iN))\n", "    plt.show()\n", "\n", "plotSum(1)\n", "plotSum(2)\n", "plotSum(3)\n", "plotSum(4)\n", "plotSum(50)\n", "plotSum(5000)\n"]}, {"cell_type": "markdown", "id": "ce376be6", "metadata": {"tags": ["learner", "md"]}, "source": ["So the sum of random numbers drawn from a uniform distribution becomes a Gaussian. This is a very important statement. Effectively, this means that any combination of random variables is a Gaussian distribution, this is crazy. We will not show the full proof here, but suffice it to say, doing the integrals gives yields the same observation. \n", "\n", "\n", "Another interesting thing to note is the standard deviation of this Gaussian is incidentally given by the (range of uniform distribution)$/\\sqrt{12}$. To verify this, for the last experiment with $N = 5000$ draws, we have\n"]}, {"cell_type": "code", "execution_count": null, "id": "5d436079", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "N = 5000\n", "unif_range = 10\n", "print(\"stddev:\", np.sqrt(N * unif_range ** 2 / 12))\n"]}, {"cell_type": "markdown", "id": "7bf5703e", "metadata": {"tags": ["learner", "md"]}, "source": ["Which matches the standard deviation we obtain numerically. To see this analytically, let's compute it \n", "\\begin{eqnarray}\n", "V[x]&=&\\int_{a}^{b}\\frac{1}{b-a}\\left(x-\\frac{b-a}{2}\\right)^2 dx\\\\\n", "V[x]&=&\\int_{-a^\\prime}^{a^\\prime}\\frac{1}{2a^\\prime}\\left(x\\right)^2 dx\\\\\n", "V[x]&=&\\frac{1}{2a^\\prime}\\frac{1}{3}\\left(x\\right)^3|_{-a^\\prime}^{a^\\prime} \\\\\n", "V[x]&=&\\frac{2a'^3}{2a^\\prime}\\frac{1}{3} \\\\\n", "V[x]&=&\\frac{\\left(\\frac{b-a}{2}\\right)^2}{3} \\\\\n", "V[x]&=&\\frac{\\left(b-a\\right)^2}{12} \\\\\n", "\\end{eqnarray}\n", "So to get the RMS of $N$ random variables summed up we have the variance is given by multiplying by $N$. Further noting that the average of $N$ summed variables gives $\\bar{x}=\\frac{b-a}{2}$. Combining all of this, we have: \n", "\\begin{eqnarray}\n", "V[x_1+x_2+...+x_N]&=& N \\frac{\\left(b-a\\right)^2}{12}\\\\\n", "V[x_1+x_2+...+x_N]&=& N \\frac{\\bar{x}^2}{3}\\\\\n", "\\end{eqnarray}\n", "This is why we can calculate the standard deviation of our sample using the above formula. In any case, we will take this demo as a proof by demo of what we call **the cental limit theorem** which states that **any distribution composed of inputs from a large number of continuous random varibles, the sum tends to a guassian**. For fun, outside of class, go ahead and derive it. Lets compare the Gaussian with a poisson distribution, so we can connect all of our friends together. \n", "\n", "Compare the poission distribution against a normal distribution for $\\lambda$=3,15,100. How do these distributions vary? "]}, {"cell_type": "code", "execution_count": null, "id": "51383fde", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#solution 1\n", "##### Lets plot a Gaussian and poisson with same mean and RMS\n", "def poisGausPlot(n):\n", "    lamb=n\n", "    k=np.arange(-2,3.0*n)\n", "    poisson=stats.poisson.pmf(k,lamb)\n", "    normal=stats.norm.pdf(k,n,math.sqrt(n))\n", "    plt.plot(k,poisson,'o',label='Poisson')\n", "    plt.vlines(k,0, poisson, color=plt.gca().lines[-1].get_color())\n", "    plt.ylim(bottom=0)\n", "    plt.plot(k,normal,'-',label='Gaussian')\n", "    plt.xlabel(\"Number of successes\")\n", "    plt.ylabel(\"Probability\")\n", "    plt.legend(loc='lower right')\n", "    plt.show()\n", "\n", "poisGausPlot(3)\n", "poisGausPlot(15)\n", "poisGausPlot(100)\n"]}, {"cell_type": "code", "execution_count": null, "id": "5cc6664b", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Generate 2 Gaussian and sum \n", "ntoys=100000\n", "sums=np.array([])\n", "for i0 in range(ntoys):\n", "    pToy = np.random.normal(0,1,2)\n", "    sums = np.append(sums,pToy.sum())\n", "_,_,binrange=normhist(sums)\n", "\n", "k=np.arange(binrange[0],binrange[-1])\n", "normal=stats.norm.pdf(k,sums.mean(),sums.std())\n", "\n", "plt.plot(k,normal,'o-')\n", "plt.xlabel(\"Number of successes\")\n", "plt.ylabel(\"Probability\")\n", "print(\"Summing: 2, numbers with mean:\",sums.mean(),\" and std-deviation\",sums.std())\n", "plt.show()\n", "#we expect a standard deviation of sqrt(2), this follows from Var(x1+x2)=N Var(x)\n", "\n", "hide_toggle()"]}, {"cell_type": "markdown", "id": "97d8b9bc", "metadata": {"tags": ["learner", "md"]}, "source": ["### Challenge Question\n", "Show that the sum of two Gaussian distributions is also Gaussian, what is its variance? "]}, {"cell_type": "markdown", "id": "6c444db1", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='exercises_2_5'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_5) | [Next Section](#section_2_6) |\n"]}, {"cell_type": "markdown", "id": "9d4cccc8", "metadata": {"tags": ["learner", "md", "catsoop_05"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 2.5.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": null, "id": "07e31baf", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "28f9cfbe", "metadata": {"tags": ["learner", "catsoop_05", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "9dffc6f2", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_2_6'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.6 Uncertainties in Measurement</h2>  \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_5) | [Exercises](#exercises_2_6) | [Next Section](#section_2_7) |\n"]}, {"cell_type": "markdown", "id": "db8fc145", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "In the previous class, we explained expectation is the mean of a distribution, and variance a measure of the width. When we perform a measurement we are are just sampling from an unkown distribution, or worse yet, we are sampling from an unknown distribution and then distorting that distribution with some sort of effect. \n", "\n", "Lets say that you are sampling a distribution that is fundamentally a Gaussian. Consider a sum of random numbers. Now on top of this, we then distort this distribution by a function $f(x)$. This distortion will modify the distribution of the events, making it less gaussian or shrinking and stretching it. A distortion funcation can arise from much things, such as from sending a particle through a magnetic field, or having light reflect off a mirror, there are countless physcial distortive effects. However, if we know $f(x)$ and we know the distribution of $x$, how does this shape of $x$ get distorted by $f(x)$. \n", "\n", "To see that consider the case when the probability of the input distribution is $p(x)$. If we define $x^{\\prime}=f(x)$,  the probability to be in small region $dx^\\prime$ of the modified coordinates is defined by \n", "\\begin{eqnarray}\n", "p^{\\prime}(x^\\prime)dx^\\prime&=&f(p(x))dx^\\prime \\\\\n", "                             &=&f(p(x))\\frac{dx^\\prime}{dx}dx\\\\\n", "                             &=&f(p(x))\\frac{df}{dx}dx\\\\\n", "\\end{eqnarray}\n", "This follows from the fact that the spread of a function sampled from $p(x)$ would be modified by the spread of $f(x)$ defined as  $f(x+\\Delta x)-f(x)\\approx\\frac{df}{dx}\\Delta x$. \n", "\n", "As a simple example, in the case of $f(x)=x^{2}$ or $\\frac{df}{dx}=2x$. What that means is that $\\sigma_{f(x)}\\approx2x\\sigma_{x}$. Lets actually see that empirically.\n"]}, {"cell_type": "code", "execution_count": null, "id": "a893e204", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Now lets say we do a measurement, and the measurement takes an input variable that is varying, \n", "#and applies a function to it. What is the spread of the function\n", "ntries=1000\n", "meas = np.full(ntries,100) #The value 100, 1k times\n", "unc  = np.random.normal (0,1, ntries) #a randomly sampled value from a Gaussian with width 1 1k times\n", "meas = meas+unc # the value 100 now smeared with sigma=1\n", "\n", "def function(ix):#our function\n", "    return ix**2\n", "outmeas = function(meas)\n", "_,_,_=normhist(outmeas)\n", "\n", "print(\"Mean:\",outmeas.mean(),\"Stddeviation:\",outmeas.std())\n", "print(\"Predicted Mean:\",function(100),\"Stddeviation:\",2*100) #expect it to be 2*100*1\n"]}, {"cell_type": "markdown", "id": "5f486d95", "metadata": {"tags": ["learner", "md"]}, "source": ["Now what about if we have two uncertainties? This is a little bit different in the sense that these variations are independent of each other. Lets consider the very simple function $f(x)=x$, now lets say that $x$ can vary by a Gaussian distributed variable $\\sigma_1$ and a second Gaussian distributed variable $\\sigma_2$. If we consider these variations, we have that $f(x)$ will be modified by\n", "\\begin{equation}\n", " f(x) = x + \\sigma_1 + \\sigma_2\n", "\\end{equation}\n", "This will give us two Gaussians. If we look to see the variance of this distribution, we can treat these two fluctuations as two independent measurements, which means we can write. \n", "\\begin{eqnarray}\n", " V[f(x)] &=& V(x) + V(\\sigma_1) + V(\\sigma_2)\\\\\n", "                &=& \\sigma_1^2 + \\sigma_2^2 \n", "\\end{eqnarray}\n", "\n", "To visualize what is going on, we can imagine plotting these variations in a 2D plot. \n", "\n"]}, {"cell_type": "code", "execution_count": null, "id": "03d9f016", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "ntoys=10000\n", "err1=np.array([])\n", "err2=np.array([])\n", "for i0 in range(ntoys):\n", "    pToy = np.random.normal(0,1,2)\n", "    err1 = np.append(pToy[0],err1)\n", "    err2 = np.append(pToy[1],err2)\n", "angle = np.linspace( 0 , 2 * np.pi , 150 ) \n", "#correct circle\n", "radius = 1*np.sqrt(2)\n", "x = radius * np.cos( angle ) \n", "y = radius * np.sin( angle ) \n", "#too large circle\n", "radius = 1*2.0\n", "x2 = radius * np.cos( angle ) \n", "y2 = radius * np.sin( angle ) \n", "\n", "plt.plot(err1,err2,\"p\")\n", "plt.plot(x,y,c='r')\n", "plt.plot(x2,y2,c='r')\n", "plt.xlabel(\"$\\sigma_{1}$\")\n", "plt.ylabel(\"$\\sigma_{2}$\")\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "b6c0903a", "metadata": {"tags": ["learner", "md"]}, "source": ["Sampling two Gaussians gives us a circular distribution with a width given by the radius of the circle. This radius, can be seen to be the standard deviation of $f(x)$ or the $\\sqrt{V[f(x)]}=\\sqrt{\\sigma_1^2+\\sigma_2^2}$, or in otherwords sampling two independent variables the variations add as if they are two separate independent coordinates. This is often denoteda as a \"Sum in Quadrature\". \n", "\n"]}, {"cell_type": "markdown", "id": "d500bd6e", "metadata": {"tags": ["learner", "md"]}, "source": ["### Challenge Question\n", "\n", "Show numerically that if $f(x) = \\log(x)$  $\\sigma_{f(x)} = \\frac{df}{dx} \\sigma_{x}$"]}, {"cell_type": "code", "execution_count": null, "id": "fcf1309a", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "ntries=100000\n", "mean=100\n", "sigma=5\n", "meas = np.full(ntries,mean) #The value 100, 1k times\n", "unc  = np.random.normal (0,sigma, ntries) #a randomly sampled value from a Gaussian with width 1 1k times\n", "meas = meas+unc # the value 100 now smeared with sigma=1\n", "\n", "def function(ix):#our function\n", "    return np.log(ix)\n", "outmeas = function(meas)\n", "_,_,_=normhist(outmeas)\n", "\n", "print(\"Mean:\",outmeas.mean(),\"Stddeviation:\",outmeas.std())\n", "print(\"Predicted Mean:\",function(mean),\"Stddeviation:\",(1./mean)*sigma)\n", "\n", "hide_toggle()\n"]}, {"cell_type": "markdown", "id": "627f6f67", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='exercises_2_6'></a>     \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_6) | [Next Section](#section_2_7) |\n"]}, {"cell_type": "markdown", "id": "5eade01e", "metadata": {"tags": ["learner", "md", "catsoop_06"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 2.6.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": null, "id": "895aea72", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "dd412324", "metadata": {"tags": ["learner", "catsoop_06", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "40b92fd5", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_2_7'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L2.7 Propagating Uncertainties</h2>     \n", "\n", "| [Top](#section_2_0) | [Previous Section](#section_2_6) | [Exercises](#exercises_2_7) |\n"]}, {"cell_type": "markdown", "id": "18427974", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>A realistic example</h3>\n", "\n", "Very famously there was an excess of events at the Tevatron collider in Fermilab. This excess caused a lot of excitement. However many people were skeptical. [Here](https://www.science20.com/quantum_diaries_survivor/no_jetjet_bump_new_cdf_diboson_analysis-123327) is a full description of what was going on. However, I would like to highight this plot here: \n", "\n", "<img src=\"http://www.pd.infn.it/~dorigo/wjjcdf73fb.jpg\" width=\"700\"/>\n", "\n", "that people thought was giving a bump for a new particle.  The way this plot is made is in two pieces. First there is a histogram of the data, that is the black points. Second the filled in areas are a histogram of the simualtion. The simulation is of all the other processes that we know are occurring, we then sum them up to get the totall prediction, the colors represent their sub predictions. This is what constitutes the solid distributions, with the different colors representing their relative contributions. Finally, on the right, we subtract the data and the solid distribution, and we get a deviation. The fact that this deviation corresponds to a bump makes us think this is a new particle. The problem with this bump is that it's a bump on a falling distribution. So what would happen if our predicted distribution was shifted to the right by a little bit, how would the bump look?\n", "\n", "To see this, lets open a file with this data and try to shift it ourselves. \n"]}, {"cell_type": "code", "execution_count": 20, "id": "6628f11e", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"data": {"image/png": "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\n", "text/plain": ["<Figure size 756x684 with 2 Axes>"]}, "metadata": {"needs_background": "light"}, "output_type": "display_data"}], "source": ["#>>>RUN\n", "\n", "import csv\n", "import matplotlib.pyplot as plt\n", "import numpy as np\n", "import urllib.request\n", "\n", "#load the file\n", "def load(iurl):\n", "    datax=np.array([])\n", "    datay=np.array([])\n", "    datayerr=np.array([])\n", "    with urllib.request.urlopen(iurl) as csvfile:\n", "        lines = [l.decode('utf-8') for l in csvfile.readlines()]\n", "        plots = csv.reader(lines, delimiter=',')\n", "        for row in plots:\n", "            datax    = np.append(datax,float(row[0]))\n", "            datay    = np.append(datay,float(row[1]))\n", "            datayerr = np.append(datayerr,np.sqrt(float(row[1])))\n", "    \n", "    return datax,datay,datayerr\n", "\n", "#compute the ratio between data and simulation\n", "def histratio(iydata,iyderr,iysim):\n", "    newydata=np.array([])\n", "    newyderr=np.array([])\n", "    for i0 in range(len(iysim)):\n", "        ynew=iydata[i0]/iysim[i0]\n", "        yner=iyderr[i0]/iysim[i0]\n", "        newydata=np.append(newydata,ynew)\n", "        newyderr=np.append(newyderr,yner)\n", "    return newydata,newyderr\n", "\n", "fig = plt.figure(figsize=(10.5, 9.5))\n", "ax = fig.add_subplot(2,1,1)\n", "datax,datay,datayerr=load(\"https://raw.githubusercontent.com/mitx-8s50/data/main/L02/tmpdata.txt\")\n", "simx,simy,simyerr=load(\"https://raw.githubusercontent.com/mitx-8s50/data/main/L02/tmpmc.txt\")\n", "plt.errorbar(datax,datay,yerr=datayerr,marker='.',c='black',linestyle = 'None')\n", "plt.plot    (datax,simy,drawstyle = 'steps-mid')\n", "ax = fig.add_subplot(2,1,2)\n", "yrdata,yrderr=histratio(datay,datayerr,simy)\n", "ax.errorbar(datax,yrdata,yerr=yrderr,marker='.',c='black',linestyle = 'None')\n", "ax.axhline(1, c='red')\n", "ax.set_ylim(0.5,1.5)\n", "plt.xlabel(\"Mjj [GeV]\")\n", "plt.ylabel(\"Data/Simulation\")\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "191c9137", "metadata": {"tags": ["learner", "md"]}, "source": ["Now we can define a shift a histogram by just shuffling events in bins. This we do by \n", "\\begin{align*}\n", "f(x^{\\prime}) & =f(x+\\sigma)\\approx f(x)+\\frac{df}{dx}\\sigma\\\\\n", " & =f(x)+\\frac{f(x+\\Delta x)-f(x)}{\\Delta x}\\sigma\\\\\n", " & =f(x)\\left(1-\\frac{\\sigma}{\\Delta x}\\right)+f(x+\\Delta x)\\frac{\\sigma}{\\Delta x}\n", "\\end{align*}\n", "Which we can rewrite in terms of bin shifts with a fractional uncertainty of $f=\\frac{\\sigma}{\\Delta x}$ this gives us\n", "\\begin{equation}\n", "\\rm{bin_{i}} = (1-f)\\rm{bin}_{i} + f \\rm{bin}_{i-1} \\\\\n", "f(x_{i}) = f(x_{i})(1-f)+f(x-\\Delta x)f\n", "\\end{equation}\n", "\n", "Let's add this modification and see if a fractional shift can explain our deviation. \n"]}, {"cell_type": "code", "execution_count": null, "id": "589ad4b2", "metadata": {"tags": ["learner", "py"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Now lets shift the bins of the simulatino by a fraction\n", "def shifthist(ixunc,isimy):\n", "    newsimy=np.array([])\n", "    for i0 in range(len(isimy)):\n", "        ynew = isimy[i0]*(1-ixunc)\n", "        if i0 > 1:\n", "            ynew = isimy[i0-1]*ixunc + isimy[i0]*(1-ixunc)\n", "        newsimy=np.append(newsimy,ynew)\n", "    return newsimy\n", "\n", "            \n", "fig = plt.figure(figsize=(10.5, 9.5))\n", "ax = fig.add_subplot(2,1,1)\n", "newsimy=shifthist(0.5,simy)\n", "plt.errorbar(datax,datay,yerr=datayerr,marker='.',c='black',linestyle = 'None')\n", "plt.plot    (datax,simy,drawstyle = 'steps-mid')\n", "plt.plot    (datax,newsimy,drawstyle = 'steps-mid')\n", "\n", "ax = fig.add_subplot(2,1,2)\n", "yrdata,yrderr=histratio(datay,datayerr,newsimy)\n", "ax.errorbar(datax,yrdata,yerr=yrderr,marker='.',c='black',linestyle = 'None')\n", "ax.axhline(1, c='red')\n", "ax.set_ylim(0.5,1.5)\n", "plt.xlabel(\"Mjj [GeV]\")\n", "plt.ylabel(\"Data/Simulation\")\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "32d1a831", "metadata": {"tags": ["learner", "md"]}, "source": ["So a fractional shift of half the bin size is sufficient to explain this effect. Do you believe it is real? "]}, {"cell_type": "markdown", "id": "d4f4dd2a", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='exercises_2_7'></a>   \n", "\n", "| [Top](#section_2_0) | [Restart Section](#section_2_7) |\n"]}, {"cell_type": "markdown", "id": "05b44fe4", "metadata": {"tags": ["learner", "md", "catsoop_07"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 2.7.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": null, "id": "c317dd41", "metadata": {"tags": ["draft", "py"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "1c2ef6df", "metadata": {"tags": ["learner", "catsoop_07", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}