{"cells": [{"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<!--start-block-->\n", "<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 1: Probability Distributions, Simple Plots, and Expectation Values</h1>\n", "\n", "<br>"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<!--start-block-->\n", "<a name='section_1_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.0 Overview</h2>"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<!--### Sections and Problems-->\n", "          \n", "<table style=\"width:100%\">\n", "    <colgroup>\n", "       <col span=\"1\" style=\"width: 40%;\">\n", "       <col span=\"1\" style=\"width: 15%;\">\n", "       <col span=\"1\" style=\"width: 45%;\">\n", "    </colgroup>\n", "    <tr>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Section</th>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Problems</th>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Summary</th>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_1_1\">L1.1 Arrays, Functions, and Simple Plots</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_1_1\">L1.1 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>create simple arrays and functions</li>\n", "                <li>introduce probability distributions</li>\n", "                <li>make simple plots</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_1_2\">L1.2 Simulated Data and Histograms</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_1_2\">L1.2 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>simulate data by randomly sampling from probability distributions</li>\n", "                <li>create histograms from randomly sampled data</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_1_3\">L1.3 Sampling Events</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_1_3\">L1.3 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>investigate the sum of randomly sampled data</li>\n", "                <li>introduce the cummulative distribution function</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_1_4\">L1.4 Expectaction and Variance</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_1_4\">L1.4 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>define the expection and variance of a distribution</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_1_5\">L1.5 Generalizing to Many Measurements</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_1_5\">L1.5 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>consider sampling from the same distribution many times</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "</table>\n", "<!--end-block-->"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "catsoop_00"]}, "source": ["<h3>Welcome!</h3>\n", "\n", "Welcome to Datascience in physics! This class will cover the core topics of how to analyze modern physics data. [more info]"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<h3>Importing Libraries</h3>\n", "\n", "Before we do anything substantial, let's make a plot. For this class, we will use `numpy`, `matplotlib` and `scipy.stats`. Please go here to make sure you can install these packages and jupyter on your computer. \n", "\n", "You can see [here](https://cs231n.github.io/python-numpy-tutorial/#python) for more info on python. Also, you can see [here]() for a quick installation [here](https://jupyter.org/install) for a jupyter install. The other packages can be installed with `pip`.  Here is a quick setup to install and load the libraries. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#import sys\n", "#we will install the core packages here\n", "#!{sys.executable} -m pip install numpy\n", "#!{sys.executable} -m pip install matplotlib\n", "#!{sys.executable} -m pip install scipy\n", "\n", "#additionally we will now load them\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import scipy.stats as stats\n", "import csv\n", "\n", "#set plot resolution\n", "%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure size\n", "plt.rcParams['figure.figsize'] = (9,6)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<!--start-block-->\n", "<a name='section_1_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.1 Arrays, Functions, and Simple Plots</h2>    \n", "    \n", "| [Top](#section_1_0) | [Previous Section](#section_1_0) | [Exercises](#exercises_1_1) | [Next Section](#section_1_2) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "To plot something, what we will do is use the numpy functions. The numpy functions are functions that can be run on arrays of objects and output arrays themselves. We will use this all the time. To put some clarity in this. Lets make an array and evaluate it. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "x = np.linspace(start=-4, stop=4, num=5)\n", "y = np.sin(x)\n", "\n", "print(x,y)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["Ok, now let's make a plot, we will plot a few distributions, a sin, cosine, and we will plot a normal distribution using the scipy stats function. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Lets plot a few random functions\n", "#First we define an x-axis\n", "x = np.linspace(start=-4, stop=4, num=100)\n", "mu = 0\n", "std = 1\n", "y = stats.norm.pdf(x, mu, std) \n", "\n", "\n", "#plotting-------------------\n", "#plot size\n", "#fig, ax = plt.subplots(figsize=(9,6)) #optionally set the figure size here\n", "\n", "#plot data\n", "plt.plot(x, np.sin(x), label='sin')\n", "plt.plot(x, np.cos(x), label='cos')\n", "plt.plot(x, y,label='normal distribution')\n", "\n", "#plot labels and style\n", "plt.title('Simple Plots of Common Functions', fontsize=15)\n", "plt.legend(loc='lower right', fontsize = 12)\n", "plt.xlabel('x', fontsize=15) #Label x\n", "plt.ylabel('f(x)', fontsize=15)#Label y\n", "\n", "# changing the fontsize of ticks\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "\n", "# a grid\n", "plt.grid()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["While, it's not the focus of this class. It is important to follow good plotting etiquette when you have a final plot. Namely, you should:\n", "- Label all axes\n", "- Label all lines with a legend (if more than one)\n", "- Make sure plot and is readable (axis ranges are right size)\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<a name='exercises_1_1'></a>\n", "\n", "| [Top](#section_1_0) | [Restart Section](#section_1_1) | [Next Section](#section_1_2) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "catsoop_01"]}, "source": ["<!--start-block-->\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 1.1.1</span>\n", "\n", "Define a function that returns the exponential of an array, using numpy.\n", "<!--end-block-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["draft"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "catsoop_01"]}, "source": ["<br>\n", "\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 1.1.2</span>\n", "\n", "Which of the following functions will generate a plot that satisfies all criteria of good plotting etiquette? Try running each function (note, this uses your previously defined function).\n", "<!--end-block-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["draft"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def plot1(x):\n", "    #plotting-------------------\n", "    #plot data\n", "    plt.plot(x, exp_func(x))\n", "\n", "    #plot labels and style\n", "    plt.xlabel('x', fontsize=15) #Label x\n", "    plt.ylabel('exp(x)', fontsize=15)#Label y\n", "\n", "    # changing the fontsize of ticks\n", "    plt.xticks(fontsize=12)\n", "    plt.yticks(fontsize=12)\n", "    \n", "    plt.show()\n", "    \n", "\n", "def plot2(x):\n", "    #plotting-------------------\n", "    #plot data\n", "    plt.plot(x, exp_func(x), label='exp(x)')\n", "\n", "    #plot labels and style\n", "    plt.title('Exponential Function', fontsize=15)\n", "    plt.legend(loc='lower right', fontsize = 12)\n", "    plt.xlabel('x', fontsize=15) #Label x\n", "    plt.ylabel('exp(x)', fontsize=15)#Label y\n", "\n", "    # changing the fontsize of ticks\n", "    plt.xticks(fontsize=12)\n", "    plt.yticks(fontsize=12)\n", "\n", "    # a grid\n", "    plt.grid()\n", "    plt.show()\n", "    \n", "    \n", "def plot3(x):\n", "    #plotting-------------------\n", "    #plot data\n", "    plt.plot(x, exp_func(x), label='exp(x)')\n", "\n", "    #plot labels and style\n", "    plt.title('Exponential Function', fontsize = 8)\n", "    plt.legend(loc='lower right', fontsize = 8)\n", "    plt.xlabel('x', fontsize=8) #Label x\n", "    plt.ylabel('exp(x)', fontsize=8)#Label y\n", "\n", "    # changing the fontsize of ticks\n", "    plt.xticks(fontsize=8)\n", "    plt.yticks(fontsize=8)\n", "\n", "    # a grid\n", "    plt.grid()\n", "    plt.show()\n", "\n", "\n", "x = np.linspace(start=0, stop=10, num=100)\n", "#plot1(x)\n", "#plot2(x)\n", "#plot3(x)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<!--start-block-->\n", "<a name='section_1_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.2 Simulated Data and Histograms</h2>\n", "    \n", "| [Top](#section_1_0) | [Previous Section](#section_1_1) | [Exercises](#exercises_1_2) | [Next Section](#section_1_3) |\n", "\n", "</br>"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["The next concept that we need to understand is a histogram. A histogram is just a sum of data points that fall within a specific range of x. We can compute it using the ```np.histogram``` function. This outputs an array with the number of events per bin along with the edges of the bin. \n", "\n", "To fill this histogram we will generate set of random events. We will use the ```np.random.uniform``` function, which generates random numbers from a uniform distribution. Then we will fill a 20-bin histogram with this info.  \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Randomly choose 1000 events between 0 and 10\n", "bkg = np.random.uniform(0,10, 1000) \n", "\n", "print(bkg)"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Now lets make a histogram\n", "histy, bin_edges = np.histogram(bkg, bins=20)\n", "bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "\n", "                            \n", "#plotting-------------------\n", "#plot size\n", "#fig, ax = plt.subplots(figsize=(9,6)) #optionally set the figure size here\n", "\n", "#plot data and axes limits\n", "plt.plot(bin_centers,histy,drawstyle = 'steps-mid')\n", "plt.ylim(0,100)\n", "#ax.set_ylim([0,100]) #set the y-range of ax to be 0 to 100, if using ax\n", "\n", "#plot labels and style\n", "plt.xlabel('x', fontsize=15) #Label x\n", "plt.ylabel('N samples', fontsize=15) #Label y\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<a name='exercises_1_2'></a>\n", "\n", "| [Top](#section_1_0) | [Restart Section](#section_1_2) | [Next Section](#section_1_3) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "catsoop_02"]}, "source": ["<!--start-block-->\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 1.2.1</span>\n", "\n", "How would you take an integral of a histogram? Complete the code below.\n", "<!--end-block-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["draft"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "integral = 0 #complete the code\n", "\n", "print(\"Integral:\",integral)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<!--start-block-->\n", "<a name='section_1_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.3 Sampling events</h2>\n", "    \n", "| [Top](#section_1_0) | [Previous Section](#section_1_2) | [Exercises](#exercises_1_3) | [Next Section](#section_1_4) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "catsoop_00"]}, "source": ["<h3>Slides</h3>\n", "\n", "<!--\n", "Please view the slides related to this lesson here: [SLIDES](https://www.dropbox.com/s/lb5695gcw1xxtpg/PCH_Lecture1_8S50.pdf?dl=0) \n", "-->\n", "\n", "Run the code below to view the slides for this lesson."]}, {"cell_type": "code", "execution_count": 1, "metadata": {"scrolled": false, "tags": ["learner"]}, "outputs": [{"data": {"text/html": ["\n", "        <iframe\n", "            width=\"975\"\n", "            height=\"550\"\n", "            src=\"https://mitx-8s50.github.io/slides/L01/slides1.html\"\n", "            frameborder=\"0\"\n", "            allowfullscreen\n", "            \n", "        ></iframe>\n", "        "], "text/plain": ["<IPython.lib.display.IFrame at 0x10f44e730>"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["#>>>RUN\n", "\n", "from IPython.display import IFrame\n", "\n", "IFrame(src='https://mitx-8s50.github.io/slides/L01/slides1.html', width=975, height=550)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<h3>Overview</h3>\n", "\n", "Now what we would like to do is something a bit more complicated. In the following notes, we are going to sample two flat distributions randomly and then define another distribution as the sum of these two distribution.  Furthermore, we are going to integrate this distribution, so we know what the total number of events. In this case, the integral is very simple. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Let's sample a uniform distribution 10k times each\n", "bkg1 = np.random.uniform(0,10, 10000)\n", "bkg2 = np.random.uniform(0,10, 10000) #this outputs an array of 10,000\n", "\n", "#Now we sum them\n", "data = bkg1+bkg2\n", "\n", "#The integral is just the length (10k)\n", "integral = len(data)\n", "\n", "def plotData(data):\n", "    #plotting-------------------\n", "    #plot size\n", "    #fig, ax = plt.subplots(figsize=(9,6)) #optionally set the figure size here\n", "    \n", "    #plot data\n", "    histy, bin_edges = np.histogram(data, bins=100)\n", "    bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "    plt.plot(bin_centers,histy,drawstyle = 'steps-mid')\n", "    \n", "    #plot labels and style\n", "    plt.xlabel('x', fontsize=15) #Label x\n", "    plt.ylabel('N samples', fontsize=15) #Label y\n", "    plt.xticks(fontsize=12)\n", "    plt.yticks(fontsize=12)\n", "    plt.show()\n", "\n", "plotData(data)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["Now, what is the distribution that we are sampling? \n", "\n", "Let's derive it analytically. However, before we do that, let's actually define a few statistical observables. \n", "\n", "To understand this, we need to define a probability distribution function, or a pdf. When we sample a uniform distribution from 0 to 10 we are taking a random number in that range. We can translate the process of taking a random sample into a distribution $p(x)$ where we define the probability $P_{ab}(X)$ as \n", "\n", "$$P_{ab}(X)=\\int_{a}^{b}p(x)dx$$\n", "\n", "or in other words the probability that a number is sampled between $a$ and $b$ is given by the integral of $p(x)$ over that range. As a consquence we have that integrating over all possibilities we have a probability of 1. \n", "\n", "$$1=\\int_{-\\infty}^{\\infty}p(x)dx$$\n", "\n", "For a flat distribution between a to b, the probability $p(x)$ is just going to be $\\frac{1}{b-a}$.  To check this. Lets just count events in our range. If we restrict our range to $x_{min} < x < x_{max}$, the probability will then just be \n", "\n", "$$\\int_{x_{min}}^{x_{max}}\\frac{1}{b-a}dx = \\frac{x_{max}-x_{min}}{b-a}$$"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#define and a=xmin and b=xmax\n", "xmin=2\n", "xmax=5\n", "\n", "#sample\n", "bkg1 = np.random.uniform(0,10, 10000)\n", "\n", "#now count\n", "prob=0\n", "total=0\n", "for x in bkg1:\n", "    total+=1\n", "    if x > xmin and x < xmax :\n", "        prob+=1\n", "        \n", "print(\"Probability that we are between a and b is: \",prob/total, \"true probability is:\",(xmax-xmin)/10)"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["So we see that we get a number very close to true. It is not exact, because now we are dealing with sampled events. We will get back to the lack of exactness going further.  \n", "\n", "Now in addition to having a pdf, we can define something called the cumulative distribution function (CDF). This function is similar to the probability, except we integrate one end of the pdf to infinity. \n", "\n", "$$\\mathrm{CDF}(x)=\\int_{x}^{\\infty}p(u)du$$\n", "\n", "This is now a function of $x$, but it actually involves an integral over the PDF. Let's make a few quick PDF and CDF distributions using the `scipy.stats` module, for the uniform and normal distributions; the normal distribution will be studied in detail in the next lecture. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#plotting-------------------\n", "#plot size\n", "fig, ax = plt.subplots(figsize=(9,6))\n", "\n", "#plot data\n", "x = np.linspace(-2,2,100)\n", "ax.plot(x, stats.uniform.pdf(x), 'k-', lw=2, label='PDF')  # PDF of a standard uniform distribution\n", "ax.plot(x, stats.uniform.cdf(x), 'k--', lw=2, label='CDF')  # CDF of a standard uniform distribution\n", "\n", "#plot labels and style\n", "plt.title(\"PDF and CDF of a standard uniform distribution\", fontsize=15)\n", "plt.legend(fontsize=12)\n", "plt.xlabel('x', fontsize=15) #Label x\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#plotting-------------------\n", "#plot size\n", "fig, ax = plt.subplots(figsize=(9,6))\n", "\n", "#plot data\n", "x = np.linspace(-5,5,100)\n", "ax.plot(x, stats.norm.pdf(x), 'k-', lw=2, label='PDF')  # PDF of a standard normal distribution\n", "ax.plot(x, stats.norm.cdf(x), 'k--', lw=2, label='CDF')  # CDF of a standard normal distribution\n", "\n", "#plot labels and style\n", "plt.title(\"PDF and CDF of a standard normal distribution\", fontsize=15)\n", "plt.legend(fontsize=12)\n", "plt.xlabel('x', fontsize=15) #Label x\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<a name='exercises_1_3'></a>\n", "\n", "| [Top](#section_1_0) | [Restart Section](#section_1_3) | [Next Section](#section_1_4) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "catsoop_03"]}, "source": ["<!--start-block-->\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 1.3.1</span>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["draft"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<!--start-block-->\n", "<a name='section_1_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.4 Expectaction and Variance</h2>\n", "\n", "| [Top](#section_1_0) | [Previous Section](#section_1_3) | [Exercises](#exercises_1_4) | [Next Section](#section_1_5) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<h3>Definitions</h3>\n", "\n", "Now, going further, this should be very familiar if you have taken quantum mechanics. Some important consquences of using pdfs is that we can define the expectation $E[x]$\n", "\n", "$$E[x]=\\int_{-\\infty}^{\\infty}xp(x)dx$$\n", "\n", "or in other words the value of $x$ weighted by its pdf. This is the **most likely value** of $x$. \n", "\n", "Furthermore, we can also define the variance of this distribution, as: \n", "\n", "$$V[x]=\\int_{-\\infty}^{\\infty}\\left(x-E[x]\\right)^{2}p(x)dx$$\n", "\n", "or in other words the spread of the numbers about the mean of the distribution. The variance is defined by the above formula, but it holds an important interpretation. This is the a measure of the width of our distribution, we often use this as a way to describe the uncertainty of our measurement. It is often taught that uncertainty is something you eyeball; its something you are literally \"uncertain\" about. That is not true. Uncertainty has a very clear definition, which is defined to be the square root of above ($\\sqrt{V(x)}$). We will clarify this more later. \n", "\n", "One important thing to get to right away though is that that the standard deviation $\\sigma$ of a variable is defined to just be the square-root of the variance. \n", "\n", "$$\\sigma=\\sqrt{V(x)}$$\n", "\n", "One last term, you will see a lot is that this called the root mean squared, or RMS.\n", "\n", "<br>"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<h3>Example of Computing Mean and Variance</h3>\n", "\n", "Let's compute the mean and variance of a flat distribution. \n", "\n", "To see how to compute this for a flat distribution, we note that for a flat distribution, we can write $p(x)=\\frac{1}{N_\\mathrm{samples}}$ within the range it is non zero (0-10 in this case). To see this we note that there is an equal probablity of any number, and the if we sample this distribution $N_\\mathrm{samples}$ times, then the probability of one sample is $\\frac{1}{N_\\mathrm{samples}}$."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Again another exercise\n", "\n", "#sample\n", "nsamples=10000\n", "bkg1 = np.random.uniform(0,10, nsamples)\n", "\n", "#mean\n", "mean=0\n", "prob=1./nsamples\n", "for x in bkg1:\n", "    mean+=x*prob\n", "print(\"Mean: \",mean)\n", "\n", "#Now we can do the variance\n", "var=0\n", "for x in bkg1:\n", "    var+=(x-mean)*(x-mean)*prob\n", "print(\"Var: \",var)\n", "\n", "#Now we can do it the fast way, using intrinsic numpy functions\n", "print(\"Mean:\",bkg1.mean(),\"Variance:\",bkg1.var())"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<h3>Example continued</h3>\n", "\n", "Ok now back to the above distribution, let's first turn a uniform distribution from 0 to 10 into a pdf. For this we know that the function is flat between 0 and 10, and zero otherwise. Consequently $f(x)=a$ when $x\\in[0,10]$, and \n", "\\begin{equation}\n", "1=\\int_{0}^{10}adx=ax|_{0}^{10}=10a\\\\\n", "a=\\frac{1}{10}\n", "\\end{equation}\n", "As a quick check we find the expectation of this distribution is \n", "\\begin{equation}\n", "E[x]=\\int_{0}^{10}axdx=ax^2|_{0}^{10}=50a\\\\\n", "E[x]=5\n", "\\end{equation}\n", "\n", "Now lets consider sampling this distribution twice. If we get a result $x^\\prime=x_{1}+x_{2}$ we have a broad range of possible solutions. Lets say $x^{\\prime}=10$ then it could be that one sample $x_{1}=5$ and the other sample $x_{2}=5$ or it could be that $x_{1}=10$ and $x_{2}=0$. To get all the possbible values for $x^{\\prime}=10$ we need to compute the expectation over all possibilities. This is equivalent imposing a constraint that $x^{\\prime}=x_{1}+x_{2}\\rightarrow x_{2}=x^{\\prime}-x_{1}$. \n", "\n", "The best way to think about this is as a 2D distribution. Lets make a plot of this. \n"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "bkg1 = np.random.uniform(0,10, 100)\n", "bkg2 = np.random.uniform(0,10, 100)\n", "\n", "#Now we sum them\n", "data = bkg1+bkg2\n", "\n", "#now lets fix x' to be 10, this means only bkg1 is an independent variable\n", "val=10-bkg1\n", "\n", "#now lets plot them\n", "#plotting-------------------\n", "#plot data\n", "plt.scatter(bkg1,bkg2, label=\"x1, x2 independently sampled\")\n", "plt.scatter(bkg1,val, label=\"x' = x1 + x2 = 10\")\n", "\n", "#plot labels and style\n", "plt.legend(fontsize=15)\n", "plt.xlabel('x1', fontsize=15) #Label x\n", "plt.ylabel('x2', fontsize=15) #Label y\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["So when we fix $x^{\\prime}$ and sample events that is equivalent to just drawing a line on the the 2D plot. Now if we think of this distribution as a 2D probability distribution function, we can write. \n", "\\begin{eqnarray}\n", "P(x_{1},x_{2})&=&\\int_{x^1_\\mathrm{min}}^{x^1_\\mathrm{max}} \\int_{x^2_\\mathrm{min}}^{x^2_\\mathrm{max}}p(x_{1})p(x_{2})dx_{1}dx_{2}\n", "\\end{eqnarray}\n", "With the probability $P$ defined now as 2D integral. In this case we treated it as 2 independent probability distriboutions $p(x_{1})$ and $p(x_{2})$. In reality this function can be a function of both variables $p(x_{1},x_{2})$. We can now simplify this distribution into a 1D distribution by integrating over the line where $x^{\\prime}=x_1+x_2$\n", "\n", "\n", "\\begin{eqnarray}\n", "p(x^\\prime=x_{1}+x_{2})&=&\\int_{-\\infty}^{\\infty}p(x_{1})p(x^\\prime-x_{1})dx_{1}\n", "\\end{eqnarray}\n", "\n", "For this we have then \n", "\\begin{eqnarray}\n", "p(x^\\prime=x_{1}+x_{2})&=&\\int_{-\\infty}^{\\infty}p(x_{1})p(x^\\prime-x_{1})dx_{1}\n", "&=&\\int_{0}^{10}\\frac{1}{a}p(x^\\prime-x_{1})dx_{1}\\\\\n", "\\end{eqnarray}\n", "Now we have to deal with several cases. The case where $x^{\\prime} > 10$ and so the smaller number cannot go down to zero, but only to a minimum of $x^{\\prime}-10$ (the max number would be 10 at that minimum. Also, we have the case where $x^\\prime \\leq 10$ and we can do the full integral. Doing this out gives us\n", "\n", "\\begin{eqnarray}\n", "&=&\\int_{x^\\prime-10}^{10}\\frac{1}{a^2}dx_{1}~\\forall x^\\prime \\geq 10\\\\\n", "&=&\\frac{20-x^\\prime}{a^2}~\\forall x^\\prime \\geq 10\\\\\n", "&=&\\frac{x^\\prime}{a^2}~\\forall x^\\prime < 10\\\\\n", "\\end{eqnarray}\n", "\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["Or, in other words, we have a line sloping up when we are below 10, and sloping down when we are above 10. To check that this is a full pdf we can then check the normalization\n", "\\begin{equation}\n", "\\int_{-\\infty}^{\\infty}p(x^\\prime)dx^{\\prime}=\\frac{x^2}{2a^2}|^{10}_{0}+\\frac{20x-x^2/2}{a^2}|^{20}_{10}\\\\\n", "1=\\frac{100}{200}+\\frac{400-200}{100}-\\frac{200-50}{100}\\\\\n", "1=\\frac{1}{2}+\\frac{200-150}{100}=1\\\\\n", "\\end{equation}\n", "\n", "The nice thing about computers is we don't need to do all these integrals to get these lines. Finally, lets actually plot all of these on the same plot! We now have a histogram and a function. \n", "\n", "There is one tricky component in the above formula is that we want to compare a distribution with a histogram, so we need to ensure that the integrals are the same, over each region.  \n", "\n", "To make sure they are the same, let pick a specific bin with minimum $x_{min}$ and maximum $x_{max}$.  Ensuring the integrals per bin are the same means is that for each bin the values need to be the same or in other words\n", "\\begin{equation}\n", "N^{\\rm bin}_\\mathrm{samples} = \\int_{x_\\mathrm{min}}^{x_\\mathrm{max}} C p(x) dx\\approx C p(x)\\left(x_\\mathrm{max}-x_\\mathrm{min}\\right) = C p(x)\\Delta x\n", "\\end{equation}\n", "Now for a distribution we can write $\\Delta x=\\frac{x_\\mathrm{max}-x_\\mathrm{min}}{N_\\mathrm{bins}}$. Additionally, if we sum all bins we have \n", "\\begin{eqnarray}\n", "N_{\\rm samples} & = & \\sum_{i=1}^{N} C p(x_{i}) \\Delta x \\\\\n", "\\end{eqnarray}\n", "Then we can write our normalization term per bin is $N_{samples}\\Delta x$. Thus, per bin we write our function as\n", "\\begin{equation}\n", "f(x)= p(x^{\\prime}) N_{\\rm samples} \\Delta x \n", "\\end{equation}"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Lets first add our numbers\n", "nsamples=1000\n", "bkg1 = np.random.uniform(0,10, nsamples)\n", "bkg2 = np.random.uniform(0,10, nsamples)\n", "data = bkg1+bkg2\n", "nbins=100\n", "\n", "#now we make a histogram\n", "histy, bin_edges = np.histogram(data, bins=nbins)\n", "bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "\n", "#Now let's define our function. \n", "def function(ix,ntot=nsamples,inbins=nbins):#note the norm is for n bins over 0-20\n", "    if ix < 10:\n", "        return ntot*(20/inbins)*(ix/100)\n", "    else: \n", "        return ntot*(20/inbins)*(20-ix)/100\n", "\n", "def functionnp(ix,ntot=nsamples,inbins=nbins):#note the norm is for n bins over 0-20\n", "    return np.where(ix < 10,ntot*(20/inbins)*(ix/100),ntot*(20/inbins)*(20-ix)/100 )\n", "    \n", "#We need to evaulate the function, so we do it like this\n", "x = np.linspace(start=0, stop=20, num=100)\n", "#this list(map) is just a trick to run this function on all elements in the array\n", "#y = np.array(list(map(function, x)))\n", "y = functionnp(x) #this just uses numpy\n", "\n", "\n", "#plotting-------------------\n", "#plot size\n", "fig, ax = plt.subplots(figsize=(9,6))\n", "\n", "#plot data\n", "plt.plot(x, y,label='analytic pdf')\n", "plt.plot(bin_centers,histy,drawstyle = 'steps-mid')\n", "\n", "#plot labels and style\n", "plt.xlabel('x1+x2', fontsize=15) #Label x\n", "plt.ylabel('$N_\\mathrm{samples}$/bin', fontsize=15) #Label y\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["Now, to understand the power of sampling, lets make a much more complicated function based on sampling, and let's see what this more complicated function looks like. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Sample something crazy\n", "bkg1 = np.random.uniform(0,10, 10000) # a random like before\n", "bkg2 = np.random.normal (5,2 , 10000) # a gaussian distribution centered about 2 with width 5\n", "data = bkg1+bkg2\n", "\n", "\n", "#plotting-------------------\n", "#plot size\n", "fig, ax = plt.subplots(figsize=(9,6))\n", "\n", "#plot data and axes limits\n", "histy, bin_edges = np.histogram(data, bins=20)\n", "bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "#ax.set_ylim([0,150])\n", "\n", "#plot labels and style\n", "plt.plot(bin_centers,histy,drawstyle = 'steps-mid')\n", "plt.xlabel('x', fontsize=15) #Label x\n", "plt.ylabel('f(x)', fontsize=15) #Label y\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["The point of this is that we can put sample events from any distribution we want, and make very complciated distributions that have all sorts of features. "]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<a name='exercises_1_4'></a>\n", "\n", "| [Top](#section_1_0) | [Restart Section](#section_1_4) | [Next Section](#section_1_5) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "catsoop_04"]}, "source": ["<!--start-block-->\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 1.4.1</span>\n", "\n", "TEXT"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["draft"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "pass"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<!--start-block-->\n", "<a name='section_1_5'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L1.5 Generalizing to many measurements</h2>\n", "    \n", "| [Top](#section_1_0) | [Previous Section](#section_1_4) | [Exercises](#exercises_1_5) |\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["Lets consider a set of measurements. Like we had with the two variables, if we take $N$ measurements, we can treat them as $N$ separate variables. Often the measurements can be sampled from the same distribution (like we had for the above case). \n", "\n", "Typically, we treat these measurements as independent variables, each from some underlying distribution. We can think of these measurements as independent, as a consquence. This means the measurement performed once doesn't affect the measurement after. The probability distributions of these is similar to the case where we had two measurements above $x_{1}$ and $x_{2}$.  Like the 2D probability distribution we had before, we now have $N$ variables, yielding an $N$ dimensional distribution. Yes! this is complicated, but don't get too scared. \n", "\n", "To deal with this very high dimensional space, we can define the joint pdf distribution of these as for two indpendent measurements its: \n", "\\begin{equation}\n", "p(x_{1},x_{2})=p(x_{1})p(x_{2}) \\\\\n", "\\end{equation}\n", "\n", "For $N$ independent measurements its, \n", "\\begin{equation}\n", "p(x_{1},...,x_{n})=\\prod_{i=0}^{i=N}p(x_{i})\n", "\\end{equation}\n", "\n", "Lets visualize some measurements sampled from the same distribution, we will take two measurements, $x_{1}$ and $x_{2}$ and, because we can, we will run this experiment 1000 times. To perform thsi experiment, we will use a normal distribution, which is defined as \n", "\\begin{equation}\n", "\\mathcal{N}(x; \\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n", "\\end{equation}\n", "This is a standard distribution that we will use *consumately* in this class. "]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "#Lets first add our numbers\n", "nsamples=1000\n", "mu=0\n", "sigma=1\n", "x1 = np.random.normal(mu,sigma, nsamples)\n", "x2 = np.random.normal(mu,sigma, nsamples)\n", "\n", "#plotting-------------------\n", "#plot size\n", "fig, ax = plt.subplots(figsize=(6,6)) #a square plotsize is more useful for this data\n", "\n", "#plot data and axes limits\n", "plt.scatter(x1,x2,)\n", "plt.xlim(-4,4)\n", "plt.ylim(-4,4)\n", "\n", "#plot labels and style\n", "plt.title(\"Joint pdf of two normal distributions\", fontsize=15)\n", "plt.xlabel('x1', fontsize=15) #Label x\n", "plt.ylabel('x2', fontsize=15) #Label y\n", "plt.xticks(fontsize=12)\n", "plt.yticks(fontsize=12)\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["Now, from this setup, we can define a bunch of variables that help to understand the data. We call the variables that we define \"observables\" or data summaries. Let's list the definition of these variables, and then we will go ahead and see what we can do with them. First, we define the mean $\\bar{x}$. \n", "\n", "\\begin{equation}\n", "\\bar{x}=\\frac{1}{N}\\sum_{i=1}^{N} x_{i}\n", "\\end{equation}\n", "\n", "To be clear, this is an observable, (i.e., a calculation), that we perform to the data that we have at hand. \n", "\n", "We can then compute the expectation of $\\bar{x}$ for our sampled distribution. This expectation gives us: \n", "\\begin{eqnarray}\n", "E[\\bar{x}]&=&\\int \\left(\\frac{1}{N}\\sum_{i=1}^{N} x_{i}\\right)\\prod_{i=0}^{i=N}p(x_{i}) dx_{i}\\\\\n", "          &=&\\frac{1}{N}\\sum_{i=1}^{N}\\left(\\int x_{j}\\prod_{i=0}^{i=N}p(x_{i}) dx_{i}\\right)\\\\\n", "          &=&\\frac{1}{N}\\times N \\int x_{i} p(x_{i}) dx_{i}\\\\\n", "E[\\bar{x}]&=&E[x]\\\\\n", "\\end{eqnarray}\n", "Or on averge $\\bar{x}$ will just be the mean of the distribution. \n", "\n", "\n", "Now, we can define the variance of the data in a similar way\n", "\\begin{equation}\n", "V(\\bar{x})=\\frac{1}{N}\\sum_{i=1}^{N} (x_{i}-\\bar{x})^{2}\n", "\\end{equation}\n", "\n", "Note that the form above is very similar to the variance of a distribution, defined by\n", "\\begin{eqnarray}\n", "E\\left[V(x)\\right]&=&\\frac{1}{N}\\int_{-\\infty}^{\\infty}\n", "\\left(\\sum_{i=1}^{N}\\left(x_{i}-\\bar{x}\\right)^{2}\\right)\\prod_{i=0}^{i=N}p(x_{i}) dx_{i}\\\\\n", "E\\left[V(x)\\right]&=&\\frac{1}{N}\\sum_{i=1}^{N}\\int_{-\\infty}^{\\infty}\\left(x_{i}-\\bar{x}\\right)^{2} p(x_{i}) dx_{i}\\\\\n", "E\\left[V(x)\\right]&=&\\frac{N}{N}E[(x-\\bar{x})^2]\\\\\n", "E\\left[V(x)\\right]&=&V(x)\\\\\n", "\\end{eqnarray}\n", "\n", "And now we can consider the variance of these distributions. Let's do the variance of our defined $\\bar{x}$. First let's derive it for just one variable. \n", "\\begin{eqnarray}\n", "V\\left[\\bar{x}\\right]&=&\\int (x_i-\\bar{x})^2 p(x_i)dx_i\\\\\n", "                     &=&\\int (x^2_i-2x_{i}\\bar{x}+\\bar{x}^2) p(x_i)dx_i\\\\\n", "                     &=&\\int x^2_i p(x_i)dx_i - 2\\bar{x}^2+\\bar{x}^2\\\\\n", "                     &=&\\int x^2_i p(x_i)dx_i -  \\bar{x}^2\\\\\n", "                     &=&\\int (x^2_i-\\bar{x}^2) p(x_i)dx_i  \n", "\\end{eqnarray}\n", "\n", "Now, lets generalize this whole thing to $N$ measurements. I would like to warn you that this is a complicated calculation, its not the focus of this class, but its here from completeness. \n", "\n", "\\begin{eqnarray}\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\sum_{i=1}^{N} x_{i}-\\bar{x}\\right)^{2} \\Pi_{i=0}^{i=N}p(x_{i}) dx_{i} \\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left( \\left(\\sum_{i=1}^{N} x_{i}\\right)^2-2N\\left(\\sum_{i=1}^{N} x_{i}\\right)\\bar{x}+ N^2\\bar{x}^2\\right)\\Pi_{i=0}^{i=N}p(x_{i}) dx_{i}\\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left( \\left(\\sum_{i=1}^{N} x_{i}\\right)^2\\right) \\Pi_{i=0}^{i=N}p(x_{i}) dx_{i}-\\frac{2}{N}\\bar{x}N\\bar{x}+\\bar{x}^2 \\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left( \\left(\\sum_{i=1}^{N} x_{i}\\right)\\left(\\sum_{i=1}^{N} x_{i}\\right) \\right) \\Pi_{i=0}^{i=N}p(x_{i}) dx_{i}-\\bar{x}^2\\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left(\\sum_{i} x_{i}^2 + 2\\sum_{i}\\sum_{j\\neq i}x_{i}x_{j} \\right) \\Pi_{i=0}^{i=N}p(x_{i}) c-\\bar{x}^2\\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left(\\sum_{i} x_{i}^2\\right)\\Pi_{i=0}^{i=N}p(x_{i})dx_{i} + \\frac{(N-1)}{N}\\bar{x}^2-\\bar{x}^2\\\\\n", "V\\left[\\bar{x}\\right]&=&\\int \\left(\\frac{1}{N}\\right)^2 \\left(\\sum_{i} x_{i}^2 -N\\bar{x}^2\\right)\\Pi_{i=0}^{i=N}p(x_{i})dx_{i} + \\frac{1}{N}\\bar{x}^2 + \\frac{(N-1)}{N}\\bar{x}^2-\\bar{x}^2\\\\\n", "V\\left[\\bar{x}\\right]&=&\\left(\\frac{1}{N}\\right) \\int \\left(\\frac{1}{N}\\right) \\left(\\sum_{i} x_{i}^2 -N\\bar{x}^2\\right)\\Pi_{i=0}^{i=N}p(x_{i})dx_{i} \\\\\n", "V\\left[\\bar{x}\\right]&=&\\left(\\frac{1}{N}\\right) \\left(\\frac{1}{N}\\right)N V(x) \\\\\n", "V\\left[\\bar{x}\\right]&=&\\left(\\frac{1}{N}\\right) V(x) \\\\\n", "\\end{eqnarray}\n", "Where $V(x)$ is the variance of any distribution. This is very important. What this means is that if we sample many times a distribution each with a variance $\\sigma^2$, we have that the variance of the average over this distribution scales as $\\frac{1}{N}$ the variance. This means that if you are measuring the mean, the uncertainty on the mean scales as the $\\sqrt{V[\\bar{x}]}=\\sqrt{\\frac{1}{N}V[x]}$. \n", "\n", "We will show without proof that that variance scales in the same way. \n", "\n", "\\begin{eqnarray}\n", "V\\left[V(\\bar{x})\\right]&=&\\left(\\frac{1}{N}\\right) V(x) \\\\\n", "\\end{eqnarray}\n", "\n", "To understand how this works, let's run some toys. \n", "\n", "<br>\n", "<!--end-block-->"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "\n", "import math\n", "\n", "#define a function that samples a normal distribution N times and then returns mean and root mean-square rms \n", "#(also known as standard deviation, the square root of variance)\n", "def sample(iN):\n", "    sample = np.random.normal(0,1,iN)\n", "    return sample.mean(),sample.std()\n", "\n", "#This function runs 100 tests where we sample N times, we call these toys\n", "def meansample(iN):\n", "    ntoys=100\n", "    allmeans=np.array([])\n", "    allrmses=np.array([])\n", "    for i0 in range(ntoys):\n", "        pMean,pRMS=sample(iN)\n", "        allmeans=np.append(allmeans,pMean)\n", "        allrmses=np.append(allrmses,pRMS)\n", "    return allmeans.std(),allrmses.std()\n", "\n", "nvar=np.array([])\n", "mean=np.array([])\n", "rms=np.array([])\n", "\n", "distmean=np.array([])\n", "distrms=np.array([])\n", "\n", "# funcrms=[]\n", "# funcmean=[]\n", "\n", "#Now we iterate from 1 to 250 in sampling and compute mean and RMS\n", "for i0 in range(250):\n", "    nvar = np.append(nvar,i0)\n", "#     funcmean.append(1./math.sqrt(1+i0))\n", "#     funcrms .append(1+1./math.sqrt(1+i0))\n", "    #Sample just once \n", "    pMean,pRMS=sample(i0)\n", "    distmean = np.append(distmean,pMean)\n", "    distrms  = np.append(distrms,pRMS)\n", "    #sample many times\n", "    pMean,pRMS=meansample(i0)\n", "    mean = np.append(mean,pMean)\n", "    rms  = np.append(rms,1+pRMS)\n", "\n", "# plt.plot(nvar,funcmean,'--',label='func rms of mean')\n", "# plt.plot(nvar,funcrms,'--',label='func rms of rms')\n", "plt.plot(nvar,distmean,label='mean')\n", "plt.plot(nvar,distrms,label='rms')\n", "plt.plot(nvar,mean,label='rms of mean')\n", "plt.plot(nvar,rms,label='rms of rms')\n", "plt.legend(loc='lower right')\n", "plt.xlabel(\"Number of samples\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner"]}, "source": ["<a name='exercises_1_5'></a>\n", "\n", "| [Top](#section_1_0) | [Restart Section](#section_1_5) |"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "catsoop_05"]}, "source": ["<!--start-block-->\n", "### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 1.5.1</span>\n", "\n", "We know that the variance and mean for a normal distribution are \n", "\n", "\\begin{eqnarray}\n", "E(\\mathcal N(x; \\mu,\\sigma)) & = & \\mu \\\\\n", "V(\\mathcal N(x; \\mu,\\sigma)) & = & \\sigma \\\\\n", "\\end{eqnarray}\n", "\n", "Now we wish to derive a functional form for $V(\\bar{x})$ and $V\\left((x-\\bar{x})^2\\right)$, and compare with simulated data.\n", "\n", "Write a function that accepts an array and returns the functional envelope that bounds the variance of the mean and the variance of the variance."]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": false, "tags": ["draft"]}, "outputs": [], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "\n", "def func_rms_mean(isample_array,imean,istdev):\n", "    rms_mean = 0. #complete the function\n", "    return rms_mean\n", "    \n", "\n", "def func_rms_rms(isample_array,imean,istdev):\n", "    #this is a piecewise function with rms=0 for isample[i]=1\n", "    rms_rms = 0. #complete the function\n", "    return np.where(isample_array <=1, 0, rms_rms)\n"]}, {"cell_type": "markdown", "metadata": {"tags": ["learner", "catsoop_05"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*Plot the functional envelop that bounds the variance of the mean and the variance of the variance and compare with simulation data.*</span>"]}, {"cell_type": "code", "execution_count": null, "metadata": {"scrolled": true, "tags": ["learner"]}, "outputs": [], "source": ["#>>>RUN\n", "# Run this cell as follow-up to the previous exercise.\n", "\n", "#make plots\n", "#####################\n", "def get_new_func_mean_rms(isamples,imean,istdev):\n", "    sample_array = np.arange(1,isamples+1,1)\n", "    \n", "    funcrmsmean = func_rms_mean(sample_array,imean,istdev)\n", "    funcrmsrms = func_rms_rms(sample_array,imean,istdev)\n", "    return funcrmsmean, funcrmsrms\n", "\n", "\n", "isamples,imean,istdev = [250,2,2]\n", "nvar, mean_mean, rms_mean, rms_rms = get_sim_mean_rms(isamples,imean,istdev)\n", "funcrmsmean, funcrmsrms = get_new_func_mean_rms(isamples,imean,istdev)\n", "\n", "\n", "\n", "def plot_mean_and_rms_mean_vals():\n", "    plt.errorbar(nvar,mean_mean,yerr=rms_mean, ecolor='red', label='mean and rms of mean')\n", "    plt.legend(loc=1)\n", "    plt.xlabel(\"Number of samples\")\n", "    plt.show()\n", "    return\n", "\n", "\n", "def plot_rms_mean_vals():\n", "    plt.plot(nvar,rms_mean,label='rms of mean')\n", "    plt.plot(nvar,funcrmsmean,'--',label='func rms of mean')\n", "    plt.legend(loc=1)\n", "    plt.xlabel(\"Number of samples\")\n", "    plt.show()\n", "    return\n", "\n", "def plot_rms_rms_vals():\n", "    plt.plot(nvar,rms_rms,label='rms of rms')\n", "    plt.plot(nvar,funcrmsrms,'--',label='func rms of rms')\n", "    plt.legend(loc=1)\n", "    plt.xlabel(\"Number of samples\")\n", "    plt.show()\n", "    return\n", "\n", "def plot_residuls():\n", "    plt.plot(nvar,funcrmsmean - rms_mean,'--',label='func rms of mean residuals')\n", "    plt.plot(nvar,funcrmsrms - rms_rms,'--',label='func rms of rms residuals')\n", "    plt.legend(loc=1)\n", "    plt.xlabel(\"Number of samples\")\n", "    plt.show()\n", "    return\n", "\n", "\n", "plot_mean_and_rms_mean_vals()\n", "plot_rms_mean_vals()\n", "plot_rms_rms_vals()\n", "plot_residuls()"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}