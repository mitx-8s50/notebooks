{"cells": [{"cell_type": "markdown", "id": "e55620a2", "metadata": {"tags": ["learner", "md"]}, "source": ["<hr style=\"height: 1px;\">\n", "<i>This notebook was authored by the 8.S50x Course Team, Copyright 2022 MIT All Rights Reserved.</i>\n", "<hr style=\"height: 1px;\">\n", "<br>\n", "\n", "<h1>Lesson 8: Fitting Neutrino Data</h1>\n"]}, {"cell_type": "markdown", "id": "a8d8edeb", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_8_0'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L8.0 Overview</h2>\n"]}, {"cell_type": "markdown", "id": "87dc485e", "metadata": {"tags": ["learner", "md"]}, "source": ["<table style=\"width:100%\">\n", "    <colgroup>\n", "       <col span=\"1\" style=\"width: 40%;\">\n", "       <col span=\"1\" style=\"width: 15%;\">\n", "       <col span=\"1\" style=\"width: 45%;\">\n", "    </colgroup>\n", "    <tr>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Section</th>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Exercises</th>\n", "        <th style=\"text-align: left; font-size: 13pt;\">Summary</th>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_8_1\">L8.1 Neutrino Oscillations</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_8_1\">L8.1 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_8_2\">L8.2 Loading the Data</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_8_2\">L8.2 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_8_3\">L8.3 Fitting the Data</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_8_3\">L8.3 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "    <tr>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#section_8_4\">L8.4 Principle Component Analysis</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\"><a href=\"#exercises_8_4\">L8.4 Exercises</a></td>\n", "        <td style=\"text-align: left; vertical-align: top; font-size: 10pt;\">\n", "            <ul>\n", "                <li>text</li>\n", "                <li>text</li>\n", "            </ul>\n", "        </td>\n", "    </tr>\n", "</table>\n", "\n"]}, {"cell_type": "markdown", "id": "fddf85fe", "metadata": {"tags": ["learner", "catsoop_00", "md"]}, "source": ["<h3>Learning Objectives</h3>\n", "\n", "Text needed\n"]}, {"cell_type": "markdown", "id": "deb93e50", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Importing Libraries</h3>\n", "\n", "Before beginning, run the cell below to import the relevant libraries for this notebook. \n", "Optionally, set the plot resolution and default figure size.\n"]}, {"cell_type": "code", "execution_count": 7, "id": "48f08691", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "import numpy as np\n", "\n", "#set plot resolution\n", "#%config InlineBackend.figure_format = 'retina'\n", "\n", "#set default figure size\n", "#plt.rcParams['figure.figsize'] = (9,6)\n"]}, {"cell_type": "markdown", "id": "d7ca6315", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_8_1'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L8.1 Neutrino Oscillations</h2>  \n", "\n", "| [Top](#section_8_0) | [Previous Section](#section_8_0) | [Exercises](#exercises_8_1) | [Next Section](#section_8_2) |\n"]}, {"cell_type": "markdown", "id": "376b1a94", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Slides</h3>\n", "\n", "Run the code below to view the slides for this section."]}, {"cell_type": "code", "execution_count": 1, "id": "0025f1f6", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"data": {"text/html": ["\n", "        <iframe\n", "            width=\"970\"\n", "            height=\"550\"\n", "            src=\"https://mitx-8s50.github.io/slides/L08/slides_L08_01.html\"\n", "            frameborder=\"0\"\n", "            allowfullscreen\n", "            \n", "        ></iframe>\n", "        "], "text/plain": ["<IPython.lib.display.IFrame at 0x10f210c40>"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["#>>>RUN\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L08/slides_L08_01.html', width=970, height=550)"]}, {"cell_type": "markdown", "id": "495247e7", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='exercises_8_1'></a>     \n", "\n", "| [Top](#section_8_0) | [Restart Section](#section_8_1) | [Next Section](#section_8_2) |\n"]}, {"cell_type": "markdown", "id": "f4bb5571", "metadata": {"tags": ["learner", "md", "catsoop_01"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 8.1.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": 13, "id": "e9daf951", "metadata": {"tags": ["draft", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "b3e8638f", "metadata": {"tags": ["learner", "catsoop_01", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "f1f6c526", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_8_2'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L8.2 Loading the Data</h2>  \n", "\n", "| [Top](#section_8_0) | [Previous Section](#section_8_1) | [Exercises](#exercises_8_2) | [Next Section](#section_8_3) |\n"]}, {"cell_type": "markdown", "id": "29a8f0fd", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Fitting Neutrino data</h3>\n", "\n", "In this part of the lecture, I would like to fit data from one of the recent Neutrino experiments. The data consists of events at various energies that are observed from neutrino matter iteractions in the NO$\\nu$A experiment in Minnesota. Details about this experiment can be found [here]( https://inspirehep.net/files/0a3cd74d55753d242b2a364ce70a5e0e). \n", "\n", "There are 3 type of neutrinos, the electron, muon and $\\tau$ neutrino. These neutrinos all interact in roughly the same way, through the weak interaction. Additionally, these neutrinos are all known to be very light. Lastly, it is found that these neutrinos are capable of changing their types over time. What that means is that an electron neutrino can oscillate into a muon neutrino and a $\\tau$ neutrino, and a muon the others, and so on. The fact that they oscillate is a bit of a mystery, but what we do know is that this means the way mass is generated for the neutrinos is a different mechanism to the way it interacts.  \n", "\n", "To uncerstand the data, we need to consider the key components of this experiment, which is that we first create a beam of neturinos at Fermilab in Illinois, and we then fire this beam at the NO$\\nu$A experiment in Minnesota. At NO$\\nu$A we check to see what we observe. Since neutrinos intract very weakly, we do this by looking a muon neutrino interactions at a detector at Fermilab, and muon neturino interactions at NO$\\nu$A. Between Fermilab and NO$\\nu$A what happens is that the neutrinos will oscillate into other neturinos through quantum mechnical mixing. This is a great way to test properties of quantum mechanics, you can read more about that [here](https://arxiv.org/abs/1602.00041). \n", "\n", "That being said, what we expect to compare is a shape by measuring the input beam, with the output shape of the observed events. Since neutrinos interact very weakly, the way we perform this is we put a large detector near the input beam, and we measure the rate of muon neutrinos ,and then we put an even larger detector at the output beam, and we then measure the rate. Lets take a look at this data. \n", "\n", "The data is in root format, like the project. We will use uproot to load the data and see what it is like.  As a reference, you can find the original data location [here](https://nova-docdb.fnal.gov/cgi-bin//ShowDocument?docid=46650)."]}, {"cell_type": "code", "execution_count": 20, "id": "47916293", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from scipy import stats\n", "!pip install uproot awkward\n", "import uproot\n", "\n", "file = uproot.open(\"NOvA_2020_data_histograms.root\")\n", "print(file.classnames())\n", "\n", "def plot(iLabel,iFile,iColor):\n", "    bin_edges = iFile[iLabel].axis().edges()\n", "    bin_centers = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "    plt.xlabel(\"E (GeV)\")\n", "    plt.ylabel(\"$N_{events}$\")\n", "    plt.errorbar(bin_centers,iFile[iLabel].values(),yerr=iFile[iLabel].errors(),marker='.',linestyle = '', color = iColor,label=iLabel)    \n", "    \n", "plot(\"neutrino_mode_numu_quartile1\",file,'black')\n", "plot(\"antineutrino_mode_numu_quartile1\",file,'red')\n", "plt.legend()\n", "plt.show()\n", "\n", "    "]}, {"cell_type": "markdown", "id": "04ce8dc6", "metadata": {"tags": ["learner", "md"]}, "source": ["So, we see two neutrino samples with four quartiles. The quartiles turn out to be different quality selections on the data. Quartile 1 is the most sensitive quartile, whereas Quartile 2,3,4 are less sensitive. How these quartiles are chosen depends on the beam, detector performance, and quality of the reconstruction. For our measurement, we can sum them all up and treat them as one measurement. \n", "\n", "The other label we see is the anti neutrino and neutrino labels are for the type of beam. The beam at fermilab can be run in two different modes. One mode is neutrino mode. In this mode, partilces are fired into the beam that mostly decay into regular neutrinos. The other mode is anti-neutrino mode, in that scenario particles are fired into the beam that decay into anti-neutrinos. \n", "\n", "Suffice it to say there is no gauarantee that anti-particles and particles oscillate with the same parameters, so we keep these samples separate. We can look at the separate quartiles, but lets do that later. \n", "\n", "Instead, lets look at another root file that has the predictions for what we expect the neutrino beam to look like. "]}, {"cell_type": "code", "execution_count": 20, "id": "e0b0249a", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "filePred = uproot.open(\"NOvA_2020_data_release_predictions_with_systs_all_hists.root\")\n", "print(filePred.classnames())\n", "plot(\"prediction_components_numu_fhc_Quartile1/NoOscillations_Total_pred\",filePred,'black')\n", "plot(\"prediction_components_numu_rhc_Quartile1/NoOscillations_Total_pred\",filePred,'red')\n", "plt.show()"]}, {"cell_type": "markdown", "id": "a4ecb0fe", "metadata": {"tags": ["learner", "md"]}, "source": ["This file is messy. I won't go into the details but let me put some labels here, to reconcile things. First of all we see prediction_components_rhc_Quartile. Quartile, is the same as before. RHC, and its counterpart FHC standard for \"Reverse Horn Current\" (RHC) and \"Foward Horn Current\".   The FHC configuration focuses charged particles with positive polarity (pions,$\\pi^{+}$ and Kaons, $K^{+}$) which decay to give a neutrino beam($\\nu_{\\mu}$) whereas, the RHC configuration focuses charged particles with opposite polarity (pions,$\\pi^{-}$ and Kaons, $K^{-}$) that decay to give an anti-neutrino enhanced beam ($\\bar{\\nu}_{\\mu}$). \n", "\n", "Furthermore, the predictions are done under the assumption that there is NoOscillations. Hence, the \"NoOscillations\" label. "]}, {"cell_type": "markdown", "id": "8ed667bd", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Neutrino Oscillations</h3>\n", "\n", "To understand how to fit this data, we follow from the master formula for neutrino oscillations. For those familiar with quantum mechanics, lets write out what the neturino particle eigen-state is:\n", "\\begin{equation}\n", " |\\nu_{\\mu}\\rangle = U^{*}_{\\mu1}|\\nu_{1}\\rangle + U^{*}_{\\mu2}|\\nu_{2}\\rangle + U^{*}_{\\mu3}|\\nu_{3}\\rangle\n", "\\end{equation}\n", "\n", "Where $U_{\\mu i}$ is the muon row of the oscilation matrix. When you time evolve this state and allow the neutrino to move forward a length $L$, you will get that(skipping some steps) \n", "\\begin{eqnarray}\n", " |\\nu_{1}(L)\\rangle = e^{-iEt-\\vec{p}\\cdot\\vec{x}}|\\nu_{1}\\rangle \\\\\n", "               \\approx e^{-i\\frac{Lm^{2}_{1}}{2E}}|\\nu_{1}(L=0)\\rangle\n", "\\end{eqnarray}\n", "and, thus, separate mass eigenstates $\\nu_{1}$, $\\nu_{2}$ and $\\nu_{3}$ will evolve at different rates because fo the $m_{1}$ term. What that means is that the probability for neutrinos to still be there can be written by the following master formula: \n", "\\begin{eqnarray}\n", " P_{\\mu\\rightarrow\\mu} & = &  \\left|\\langle\\nu_{\\mu}(L)|\\nu_{\\mu}(0)\\rangle\\right|^{2} \\\\\n", "                       & \\approx & 1-\\sin^{2}\\theta_{23}\\sin^{2}\\left(\\frac{1.27\\Delta m^{2}_{23}}{E} L\\right)  \n", "\\end{eqnarray}\n", "Where $\\sin^{2}\\theta_{23}$ is the parameter that describes the rate of oscillation between muon neutrinos and $\\tau$ neutrinos, and $m^{2}_{23}=m_{3}^2-m_{2}^2$ is the mass difference between the $\\tau$ and muon neutrino. You may ask, why is the electron neutrino not involved. It turns out that its rate of oscillations don't impact this measurement. \n", "\n", "Given that, what we can do then is take our original data, divide it by our no oscillation expectation and fit it. In this case, what we would like to extract is not just one parameter, but two parameters $\\theta_{23}$ and $m^{2}_{23}$. Let's see if we can get them. \n", "\n", "First, lets prepare our ratio data. First thing is to construct the ratio for each quantile."]}, {"cell_type": "code", "execution_count": 20, "id": "6e7e290a", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "nquartiles=4\n", "label=\"neutrino_mode_numu_quartile\"\n", "predlabel0=\"prediction_components_numu_fhc_Quartile\"\n", "predlabel1=\"/NoOscillations_Total_pred\"\n", "bin_edges=file[label+\"1\"].axis().edges()\n", "x = 0.5*(bin_edges[1:] + bin_edges[:-1])\n", "def ratio(iQuartile,iPlot=False):\n", "    ytop=file[label+str(i0+1)].values()\n", "    ytop_err=file[label+str(i0+1)].values()\n", "    ybot=filePred[predlabel0+str(i0+1)+predlabel1].values()\n", "    #ybot_err=file[label+str(i0+1)].values() we will skip this since the error is much smaller\n", "    y = ytop/ybot\n", "    y_err = ytop_err/ybot\n", "    if iPlot:\n", "        plt.errorbar(x,y,yerr=y_err,marker='.',linestyle = '',label=\"Quartile \"+str(i0+1))\n", "    return y,y_err\n", "    \n", "for i0 in range(nquartiles):\n", "    ratio(i0,True)\n", "    \n", "plt.xlabel(\"E(GeV)\")\n", "plt.ylabel(\"Ratio\")\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "id": "685fbef7", "metadata": {"tags": ["learner", "md"]}, "source": ["Now, what we would like to do is combine these ratios together. However, we need to do a weighted average weighted by their uncertainties. To do that, we will define for the i-th bin in the ratio $r_{i}$ for the j-th quartile, the [weighted mean](https://en.wikipedia.org/wiki/Weighted_arithmetic_mean)\n", "\\begin{equation}\n", " \\bar{r}_{i} = \\frac{1}{\\sum_{j=1}^{4} \\frac{1}{\\sigma^{2}_{ij}} }\\sum_{j=1}^{4} \\frac{1}{\\sigma^{2}_{ij}} r_{ij}\n", "\\end{equation}\n", "This is the maximum likelihood mean for normally distributed independent variables (see above). The weighted variance is then given by propagation of errors as\n", "\n", "\\begin{equation}\n", " \\sigma^{2}_{i} = \\left(\\frac{1}{\\sum_{j=1}^{4} \\frac{1}{\\sigma^{2}_{ij}} }\\right)^{2}\\sum_{j=1}^{4} \\frac{1}{\\sigma^{4}_{ij}} \\sigma^{2}_{ij} \\\\\n", "  \\sigma^{2}_{i} = \\left(\\frac{1}{\\sum_{j=1}^{4} \\frac{1}{\\sigma^{2}_{ij}} }\\right)^{2}\\sum_{j=1}^{4} \\frac{1}{\\sigma^{2}_{ij}} \\\\\n", "\\sigma^{2}_{i} = \\left(\\frac{1}{\\sum_{j=1}^{4} \\frac{1}{\\sigma^{2}_{ij}} }\\right)\n", "\\end{equation}\n"]}, {"cell_type": "code", "execution_count": 20, "id": "380082a9", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "def combinedRatio():\n", "    y,y_err = ratio(0,False)\n", "    y_arrs=np.array([y])\n", "    weight_arrs=np.array([y_err])\n", "    for i0 in range(nquartiles-1):\n", "        y,y_err = ratio(i0,False)\n", "        y_arrs=np.vstack([y_arrs,y])\n", "        weights=1./(y_err**2)\n", "        weights[weights == np.inf] = 0.1\n", "        weight_arrs = np.vstack([weight_arrs,weights])\n", "    #Now do the weighted \n", "    yout=np.average(y_arrs,weights=weight_arrs,axis=0)\n", "    weights=np.sum(weight_arrs,axis=0)\n", "    return yout,1/weights**0.5,weights**0.5\n", "\n", "label=\"neutrino_mode_numu_quartile\"\n", "predlabel0=\"prediction_components_numu_fhc_Quartile\"\n", "y,yerr,weights=combinedRatio()    \n", "\n", "label=\"antineutrino_mode_numu_quartile\"\n", "predlabel0=\"prediction_components_numu_rhc_Quartile\"\n", "y_anti,yerr_anti,weights_anti=combinedRatio()    \n", "\n", "plt.errorbar(x,y,yerr=yerr,marker='.',linestyle = '',label=\"neutrino\")\n", "plt.errorbar(x,y_anti,yerr=yerr_anti,marker='.',linestyle = '',label=\"anti-neutrino\")\n", "plt.xlabel(\"E(GeV)\")\n", "plt.ylabel(\"Ratio\")\n", "plt.legend()\n", "plt.ylim(0,1.5)\n", "plt.show()"]}, {"cell_type": "markdown", "id": "30b426bb", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='exercises_8_2'></a>     \n", "\n", "| [Top](#section_8_0) | [Restart Section](#section_8_2) | [Next Section](#section_8_3) |\n"]}, {"cell_type": "markdown", "id": "6005913d", "metadata": {"tags": ["learner", "md", "catsoop_02"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 8.2.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": 23, "id": "42490d28", "metadata": {"tags": ["draft", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "5944e044", "metadata": {"tags": ["learner", "catsoop_02", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "bea5e05f", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_8_3'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L8.3 Fitting the Data</h2>  \n", "\n", "| [Top](#section_8_0) | [Previous Section](#section_8_2) | [Exercises](#exercises_8_3) | [Next Section](#section_8_4) |\n"]}, {"cell_type": "markdown", "id": "55dd2e62", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Slides</h3>\n", "\n", "Run the code below to view the slides for this section."]}, {"cell_type": "code", "execution_count": 1, "id": "31df0081", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"data": {"text/html": ["\n", "        <iframe\n", "            width=\"970\"\n", "            height=\"550\"\n", "            src=\"images/slides_L08_03.html\"\n", "            frameborder=\"0\"\n", "            allowfullscreen\n", "            \n", "        ></iframe>\n", "        "], "text/plain": ["<IPython.lib.display.IFrame at 0x10f1299d0>"]}, "execution_count": 1, "metadata": {}, "output_type": "execute_result"}], "source": ["#>>>RUN\n", "\n", "from IPython.display import IFrame\n", "IFrame(src='https://mitx-8s50.github.io/slides/L08/slides_L08_03.html', width=970, height=550)"]}, {"cell_type": "markdown", "id": "e74ddafd", "metadata": {"tags": ["learner", "md"]}, "source": ["Ok, now that we have the points, lets finally fit the data."]}, {"cell_type": "code", "execution_count": 20, "id": "a9dc1189", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "import lmfit\n", "deltam=1*1e-3\n", "L=810\n", "sin2theta23=1.0\n", "def func(x,scale1,scale2):\n", "    xval=1.27*deltam*scale1*L/x\n", "    #val=1-4*scale2*sin2theta23*(1-scale2*sin2theta23)*np.sin(xval)**2\n", "    val=1-4*scale2*(1-scale2)*(np.sin(xval)**2)\n", "    return val\n", "\n", "def fit(iX,iY,iWeight):\n", "    model  = lmfit.Model(func)\n", "    p = model.make_params(scale1=1.0,scale2=0.6)\n", "    result = model.fit(x=iX[iY > 0],data=iY[iY > 0], params=p, weights=iWeight[iY > 0])\n", "    lmfit.report_fit(result)\n", "    result.plot()\n", "    print(\"Fit1 chi2 probability: \",stats.chi2.cdf(result.chisqr,result.nfree))\n", "\n", "fit(x,y,weights)\n", "fit(x,y_anti,weights_anti)"]}, {"cell_type": "markdown", "id": "ac79d62a", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Profiling Neutrino Parameters</h3>\n", "\n", "So we see that neutrinos oscillate. However, what if we want to undrstand how the values of the parameters vary. Lets do a quick scan of the parameters, computing the likelihood for each. \n", "\n", "We can write the 2x the likelihood in terms of the  as the $\\chi^{2}$: \n", "\n", "\\begin{eqnarray}\n", "\\chi^{2}(x|\\vec{\\theta}) &=& \\sum_{i=1}^{N} \\frac{(x_{i}-f(x_{i}|\\vec{\\theta})^2}{\\sigma_{i}^{2}} \\\\\n", "-2 \\log\\left(\\mathcal{L}(x|\\vec{\\theta})\\right) &=& \\sum_{i=1}^{N} \\frac{(x_{i}-f(x_{i}|\\vec{\\theta})^2}{\\sigma_{i}^{2}} \\\\\n", "\\end{eqnarray}"]}, {"cell_type": "code", "execution_count": 20, "id": "643d28f0", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "def twoLogLike(var,iX=x,iY=y,iWeights=weights):\n", "    lTot=0\n", "    xtest=func(iX,var[1],var[0])\n", "    lTot = weights*(iY-xtest)\n", "    return np.sum(lTot**2)\n", "\n", "from scipy import optimize as opt\n", "x0 = np.array([1,1])\n", "sol=opt.minimize(twoLogLike, x0)\n", "\n", "def plotScan(sol):\n", "    #Look the same answers, now lets plot the chi2\n", "    xscan = np.linspace(sol.x[0]*0.6,sol.x[0]*2.5, 100)\n", "    yscan = np.linspace(sol.x[1]*0.6,sol.x[1]*2.0, 100)\n", "    X, Y = np.meshgrid(xscan, yscan)\n", "    levels = [0.1,1,2.3,4,9, 16, 25, 36, 49, 64, 81, 100]\n", "    for i0 in range(len(levels)):\n", "        levels[i0] = levels[i0]+sol.fun\n", "    Z = np.array([twoLogLike([xscan,yscan]) for (xscan,yscan) in zip(X.ravel(), Y.ravel())]).reshape(X.shape)\n", "    fig, ax = plt.subplots(1, 1)\n", "    c = ax.pcolor(X,Y,Z,cmap='RdBu')\n", "    fig.colorbar(c, ax=ax)\n", "    c = plt.contour(X, Y, Z, levels,colors=['red', 'blue', 'yellow','green'])\n", "    plt.xlabel(\"$\\sin^{2}\\Theta_{23}$\")\n", "    plt.ylabel(\"$\\Delta m^{2}_{23}$\")\n", "    plt.show()\n", "\n", "plotScan(sol)"]}, {"cell_type": "markdown", "id": "0ee83b8f", "metadata": {"tags": ["learner", "md"]}, "source": ["So now, we see two circles, what exactly does this mean. Lets profile one variable at a time. "]}, {"cell_type": "code", "execution_count": 20, "id": "304295d1", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "#Now lets fix one parameter at the minimum, and profile the other\n", "def scanAxes(sol):\n", "    xscan = np.linspace(sol.x[0]*0.8,sol.x[0]*2.2, 100)\n", "    yscan = np.linspace(sol.x[1]*0.8,sol.x[1]*1.2, 100)\n", "\n", "    xLog = np.array([])\n", "    for pX in xscan:\n", "        xLog = np.append(xLog,twoLogLike(var=[pX,sol.x[1]]))\n", "\n", "    yLog = np.array([])\n", "    for pY in yscan:\n", "        yLog = np.append(yLog,twoLogLike(var=[sol.x[0],pY]))\n", "\n", "    plt.plot(xscan, xLog,label='loglike');\n", "    plt.axhline(sol.fun+1, c='red')\n", "    plt.xlabel(\"$\\sin^{2}\\Theta_{23}$\")\n", "    plt.ylabel(\"2$\\Delta$LL\")\n", "    plt.show()\n", "\n", "    #Now for the other parameter\n", "    plt.plot(yscan,yLog,label='LL');\n", "    plt.axhline(sol.fun+1, c='red')\n", "    plt.xlabel(\"$\\Delta m^{2}_{23}$\")\n", "    plt.ylabel(\"2$\\Delta$LL\")\n", "    plt.show()\n", "    \n", "scanAxes(sol)"]}, {"cell_type": "markdown", "id": "898a0c7e", "metadata": {"tags": ["learner", "md"]}, "source": ["So for $\\sin^{2}(\\theta_{23})$ there are actually two minima. "]}, {"cell_type": "markdown", "id": "9400310e", "metadata": {"tags": ["learner", "md"]}, "source": ["### Challenge Question\n", "\n", "Do the scan for anti-neutrino, do you see a difference in parameters?  A difference in the parameters would mean that anti particles behave differently that regular particles. This is known as [CP-violation](https://en.wikipedia.org/wiki/CP_violation) and can possibly explain why the universe is made of predominatly matter!"]}, {"cell_type": "code", "execution_count": 20, "id": "e40c8131", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#answer\n", "def twoLogLike(var,iX=x,iY=y_anti,iWeights=weights_anti):\n", "    lTot=0\n", "    xtest=func(iX,var[1],var[0])\n", "    lTot = weights*(iY-xtest)\n", "    return np.sum(lTot**2)\n", "\n", "x0 = np.array([1,1])\n", "sol=opt.minimize(twoLogLike, x0)\n", "plotScan(sol)\n", "scanAxes(sol)"]}, {"cell_type": "markdown", "id": "e76db872", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Combining measurements with constraints from the world</h3>\n", "\n", "Now lets say, we want to combine this measurment with another measurement. This simplest way to imagine this is that we are minimizing our fit with an additional bin, which is the likelihood that our measurement has deviated from the world average. Our likelihood now will be the product of the probabilities of the best fit parameters, with the new results from NO$\\nu$A.  We can write this as\n", "\n", "\\begin{equation}\n", "2 \\log\\left(\\mathcal{L}(x|\\vec{\\theta})\\right) = 2 \\log\\left(\\mathcal{L}(x|\\vec{\\theta})\\right)_{\\rm original} + \n", "\\frac{\\left(\\sin \\theta_{23} - \\sin \\theta_{23}^{\\rm best}\\right)^{2}}{\\sigma^{2}_{\\sin \\theta_{23}}} + \\frac{\\left(\\Delta m^{2}_{23} - \\Delta m^{2~\\rm{best}}_{23}\\right)^{2}} {\\sigma^{2~\\rm{best}}_{\\Delta m^{2}_{12}}}\n", "\\end{equation}"]}, {"cell_type": "code", "execution_count": 20, "id": "3207cea2", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "#Now what if we try to add the world's measurement of these parameters into our fit\n", "#https://pdg.lbl.gov/2020/listings/rpp2020-list-neutrino-mixing.pdf\n", "def twoLogLike(var,iX=x,iY=y,iWeights=weights):\n", "    lTot=0\n", "    xtest=func(iX,var[1],var[0])\n", "    lTot = weights*(iY-xtest)\n", "    lTot = np.sum(lTot**2)\n", "    sin2worldavg=0.547\n", "    sin2uncavg=0.021\n", "    constraintsin2=((var[0]-sin2worldavg)**2)/(sin2uncavg**2)\n", "    deltamworldavg=2.453\n", "    deltamuncavg=0.034\n", "    constraintdeltam=((var[1]-deltamworldavg)**2)/(deltamuncavg**2)\n", "    return lTot+constraintsin2+constraintdeltam\n", "\n", "x0 = np.array([1,1])\n", "sol=opt.minimize(twoLogLike, x0)\n", "plotScan(sol)\n", "scanAxes(sol)"]}, {"cell_type": "code", "execution_count": 20, "id": "5add9c87", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "def scanAxes(sol):\n", "    xscan = np.linspace(sol.x[0]*0.9,sol.x[0]*1.2, 100)\n", "    yscan = np.linspace(sol.x[1]*0.9,sol.x[1]*1.1, 100)\n", "\n", "    xLog = np.array([])\n", "    for pX in xscan:\n", "        xLog = np.append(xLog,twoLogLike(var=[pX,sol.x[1]]))\n", "\n", "    yLog = np.array([])\n", "    for pY in yscan:\n", "        yLog = np.append(yLog,twoLogLike(var=[sol.x[0],pY]))\n", "\n", "    plt.plot(xscan, xLog,label='loglike');\n", "    plt.axhline(sol.fun+1, c='red')\n", "    plt.xlabel(\"$\\sin^{2}\\Theta_{23}$\")\n", "    plt.ylabel(\"2$\\Delta$LL\")\n", "    plt.show()\n", "\n", "    #Now for the other parameter\n", "    plt.plot(yscan,yLog,label='LL');\n", "    plt.axhline(sol.fun+1, c='red')\n", "    plt.xlabel(\"$\\Delta m^{2}_{23}$\")\n", "    plt.ylabel(\"2$\\Delta$LL\")\n", "    plt.show()\n", "    \n", "scanAxes(sol)"]}, {"cell_type": "markdown", "id": "0cc5524a", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='exercises_8_3'></a>     \n", "\n", "| [Top](#section_8_0) | [Restart Section](#section_8_3) | [Next Section](#section_8_4) |\n"]}, {"cell_type": "markdown", "id": "9c7f033a", "metadata": {"tags": ["learner", "md", "catsoop_03"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 8.3.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": 33, "id": "ca709dc7", "metadata": {"tags": ["draft", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "6052422d", "metadata": {"tags": ["learner", "catsoop_03", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}, {"cell_type": "markdown", "id": "ccf8b9ba", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='section_8_4'></a>\n", "<hr style=\"height: 1px;\">\n", "\n", "## <h2 style=\"border:1px; border-style:solid; padding: 0.25em; color: #FFFFFF; background-color: #90409C\">L8.4 Principle Component Analysis</h2>     \n", "\n", "| [Top](#section_8_0) | [Previous Section](#section_8_3) | [Exercises](#exercises_8_4) |\n"]}, {"cell_type": "markdown", "id": "7ad5ebb4", "metadata": {"tags": ["learner", "md"]}, "source": ["<h3>Overview</h3>\n", "\n", "Finally, I would like to say that this method of finding the ellipse is our first deep learning method.\n", "This procedure of computing the covariance matrix, and finding the eigenvectors is known as  principle component analysis or PCA. Lets run it on our example and look From https://jakevdp.github.io/PythonDataScienceHandbook/05.09-principal-component-analysis.html\n", "\n", "First, what we can do is look at our old correlated fit. All this will do is get the eigenvectors and values for our 2D plot."]}, {"cell_type": "code", "execution_count": 40, "id": "da6299cf", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "from sklearn.decomposition import PCA\n", "X=(np.vstack([lAs,lBs])).T\n", "pca = PCA(n_components=2)\n", "pca.fit(X)\n", "print(\"PCA vectors\")\n", "print(pca.components_)\n", "print(\"PCA values\")\n", "print(pca.explained_variance_)\n", "print(\"Old Eigen\",\"vectors\",w,\"values\",v)\n", "\n", "def draw_vector(v0, v1, ax=None):\n", "    ax = ax or plt.gca()\n", "    arrowprops=dict(arrowstyle='->',linewidth=2,shrinkA=0, shrinkB=0)\n", "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n", "\n", "# plot data\n", "plt.scatter(lAs, lBs, alpha=0.2)\n", "for length, vector in zip(pca.explained_variance_, pca.components_):\n", "    v = vector * 3 * np.sqrt(length)\n", "    draw_vector(pca.mean_, pca.mean_ + v)\n", "plt.axis('equal');"]}, {"cell_type": "markdown", "id": "9466f4d9", "metadata": {"tags": ["learner", "md"]}, "source": ["Finally, we can try this on an ML dataset. Lets take images with many pixels and treat each pixel as a separate dimension. We can then run the decomposition on the image by decomposing the n-pixel by n-pixel correlation matrix."]}, {"cell_type": "code", "execution_count": 40, "id": "a44b5b9b", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "#Now lets do it ML style for fun\n", "#Load some faces of images\n", "from sklearn.datasets import fetch_lfw_people\n", "faces = fetch_lfw_people(min_faces_per_person=60)\n", "\n", "fig, axes = plt.subplots(3, 8, figsize=(9, 4),subplot_kw={'xticks':[], 'yticks':[]},gridspec_kw=dict(hspace=0.1, wspace=0.1))\n", "#Lets plot the eigenvectors\n", "for i, ax in enumerate(axes.flat):\n", "    ax.imshow(faces.data[i].reshape(62, 47), cmap='bone')\n", "    \n", "#Fit them to PCA \n", "from sklearn.decomposition import PCA as RandomizedPCA\n", "pca = RandomizedPCA(200)\n", "pca.fit(faces.data)\n", "fig, axes = plt.subplots(3, 8, figsize=(9, 4),subplot_kw={'xticks':[], 'yticks':[]},gridspec_kw=dict(hspace=0.1, wspace=0.1))\n", "#Lets plot the eigenvectors\n", "for i, ax in enumerate(axes.flat):\n", "    ax.imshow(pca.components_[i].reshape(62, 47), cmap='bone')\n", "plt.show()\n", "    \n", "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n", "plt.xlabel('number of components')\n", "plt.ylabel('cumulative explained variance');\n", "plt.show()\n"]}, {"cell_type": "markdown", "id": "b36fa308", "metadata": {"tags": ["learner", "md"]}, "source": ["Finally, what we can do is plot our world leaders just by taking the first 80 eigenvectors of our sample. What we have effectively done is compress our original image into 80 values thats it!"]}, {"cell_type": "code", "execution_count": 40, "id": "4aef11c5", "metadata": {"tags": ["learner", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>RUN\n", "\n", "# Compute the components and projected faces\n", "pca = RandomizedPCA(80).fit(faces.data)\n", "components = pca.transform(faces.data)\n", "projected = pca.inverse_transform(components)\n", "\n", "# Plot the results\n", "fig, ax = plt.subplots(2, 10, figsize=(10, 2.5),subplot_kw={'xticks':[], 'yticks':[]},gridspec_kw=dict(hspace=0.1, wspace=0.1))\n", "for i in range(10):\n", "    ax[0, i].imshow(faces.data[i].reshape(62, 47), cmap='binary_r')\n", "    ax[1, i].imshow(projected[i].reshape(62, 47), cmap='binary_r')\n", "    \n", "ax[0, 0].set_ylabel('full-dim\\ninput')\n", "ax[1, 0].set_ylabel('80-dim\\nreconstruction');\n"]}, {"cell_type": "markdown", "id": "deac0a95", "metadata": {"tags": ["learner", "md"]}, "source": ["<a name='exercises_8_4'></a>   \n", "\n", "| [Top](#section_8_0) | [Restart Section](#section_8_4) |\n"]}, {"cell_type": "markdown", "id": "d6cb0a10", "metadata": {"tags": ["learner", "md", "catsoop_04"]}, "source": ["### <span style=\"border:3px; border-style:solid; padding: 0.15em; border-color: #90409C; color: #90409C;\">Exercise 8.4.1</span>\n", "\n", "text\n"]}, {"cell_type": "code", "execution_count": 43, "id": "de41afee", "metadata": {"tags": ["draft", "py"]}, "outputs": [{"name": "stdout", "output_type": "stream", "text": []}], "source": ["#>>>EXERCISE\n", "# Use this cell for drafting your solution (if desired),\n", "# then enter your solution in the interactive problem online to be graded.\n", "\n", "def exp_func(x):\n", "    return 0\n"]}, {"cell_type": "markdown", "id": "aff69986", "metadata": {"tags": ["learner", "catsoop_04", "md"]}, "source": ["### <span style=\"color: #90409C;\">*>>> Follow-up (ungraded)*</span>\n", "\n", "    \n", "><span style=\"color: #90409C;\">*TEXT*</span>\n"]}], "metadata": {"celltoolbar": "Tags", "kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.9.9"}}, "nbformat": 4, "nbformat_minor": 5}